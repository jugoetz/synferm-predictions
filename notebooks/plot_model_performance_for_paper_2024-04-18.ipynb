{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot model performance\n",
    "\n",
    "Visualize performance on different models on data `2024-04-18` from the wandb API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path().absolute().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import wilcoxon\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "from utils import get_runs_as_list\n",
    "from src.util.definitions import DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "sns.set_theme(context=\"paper\", \n",
    "              style=\"white\", \n",
    "              font_scale=1, #0.7,\n",
    "              rc={\"savefig.transparent\": True, \n",
    "                  \"axes.grid\": False, \n",
    "                  \"axes.spines.bottom\": True,\n",
    "                  \"axes.spines.left\": False,\n",
    "                  \"axes.spines.right\": False,\n",
    "                  \"axes.spines.top\": False,\n",
    "                  \"font.family\":'sans-serif',\n",
    "                  \"font.sans-serif\":[\"Helvetica\", \"Arial\"],\n",
    "                  \"xtick.major.pad\": 0.0,\n",
    "                  \"xtick.minor.pad\": 0.0,\n",
    "                  \"ytick.major.pad\": 0.0,\n",
    "                  \"ytick.minor.pad\": 0.0,\n",
    "                  \"axes.labelweight\": \"bold\",\n",
    "                  \"axes.labelpad\": 2.5,  # standard is 4.0\n",
    "                  \"axes.xmargin\": .05,\n",
    "                 }, \n",
    "             )\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 6,\n",
    "    'axes.titlesize': 6,\n",
    "    'xtick.labelsize': 6,\n",
    "    'ytick.labelsize': 6,\n",
    "    'legend.fontsize': 6,\n",
    "    'font.size': 6,\n",
    "    'svg.fonttype': 'none',  # necessary to have editable text in SVGs\n",
    "    'text.color': 'black',\n",
    "    'axes.labelcolor': 'black',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "# more settings for all plots\n",
    "errorbar = \"se\"  # standard error of the mean\n",
    "errwidth = .9\n",
    "errcolor = \"black\"\n",
    "capsize = .1  # size of the end of the errorbar\n",
    "linewidth = 1.  # width of the outline of barplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get data from wandb API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list, config_list, tag_list, name_list  = get_runs_as_list(\n",
    "    filters={\n",
    "        \"$and\": [\n",
    "                {\"$or\":\n",
    "                     [\n",
    "                         {\"jobType\": \"training\"},\n",
    "                         {\"jobType\": \"hparam_best\"}\n",
    "                     ]\n",
    "                },\n",
    "            {\"createdAt\": {\"$gt\": \"2024-03-30\"}}\n",
    "        ],\n",
    "    },\n",
    "    timeout=59,\n",
    ")\n",
    "df_all = pd.json_normalize(config_list).merge(pd.json_normalize(summary_list), left_index=True, right_index=True)\n",
    "df_all[\"tags\"] = tag_list\n",
    "df_all[\"run_id\"] = name_list\n",
    "df_all[\"run_group\"] = [s.rsplit(\"_\", maxsplit=1)[0] for s in name_list]\n",
    "df_all[\"Model+Features\"] = df_all[\"name\"] + \"/\" + df_all[\"decoder.global_features\"].str.join(\"+\").str.replace(\"None\", \"CGR\")\n",
    "df_all[\"fold\"] = df_all[\"run_id\"].str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all experiment ids in the queried data\n",
    "\", \".join(sorted(df_all[\"experiment_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for relevant data (JG1527 onwards for 2024-04-18 models)\n",
    "# n.b. just a doublecheck, the date filter in the query should take care of this\n",
    "df_all = df_all.loc[df_all[\"experiment_id\"].apply(lambda x: int(x.strip(\"JG\")) > 1526 if isinstance(x, str) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available experiments by split\n",
    "for tag, row in df_all.groupby(\"tags\")[[\"experiment_id\"]].agg(set).iterrows():\n",
    "    print(tag, \"-->\", row[\"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dir where we will save plots\n",
    "analysis_dir = pathlib.Path(\"results\")\n",
    "# set date (of the dataset) for saving\n",
    "datadate = \"2024-04-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stats = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "\n",
    "def get_chance_ap(split_name, fold=None, set_type=\"test\"):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    if fold is not None:\n",
    "        return df.loc[(df[\"split_name\"] == split_name ) & (df[\"fold\"] == fold), f\"Chance level average precision macro on {set_type} set\"].item()\n",
    "    else:\n",
    "        return df.loc[(df[\"split_name\"] == split_name ), f\"Chance level average precision macro on {set_type} set\"].mean()\n",
    "    \n",
    "def get_sample_count(split_name, fold=None):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    if fold is not None:\n",
    "        return int(df.loc[(df[\"split_name\"] == split_name) & (df[\"fold\"] == fold), \"Train samples\"].item().split()[0])\n",
    "    else:\n",
    "        return int(df.loc[df[\"split_name\"] == split_name, \"Train samples\"].str.split(expand=True)[0].astype(\"int\").mean())    \n",
    "    \n",
    "        \n",
    "def get_buildingblock_count(split_name, fold=None, bb_types=[\"initiators\", \"monomers\", \"terminators\"]):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    for s in bb_types:\n",
    "        if s not in [\"initiators\", \"monomers\", \"terminators\"]:  # catch incorrect options for bulding blocks\n",
    "            raise ValueError(\"This building block type does not exist\")\n",
    "    columns = [f\"Train {s}\" for s in bb_types]\n",
    "    if fold is not None:\n",
    "        return df.loc[(df[\"split_name\"] == split_name) & (df[\"fold\"] == fold), columns].mean(axis=None)\n",
    "    else:\n",
    "        return df.loc[df[\"split_name\"] == split_name, columns].mean(axis=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we have the expected number of experiments (catch duplicated or unfinished runs)\n",
    "for exp_id in df_all[\"experiment_id\"].unique():\n",
    "    n_exp = (df_all[\"experiment_id\"] == exp_id).sum()\n",
    "    if n_exp != 9:\n",
    "        print(f\"Warning: Expected 9 experiments for {exp_id}, found {n_exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = \"#4b4c68\"  # blue\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1697\",  # LogReg/FP\n",
    "    \"JG1700\",  # LogReg/RDKit\n",
    "    \"JG1698\",  # AttentiveFP/CGR\n",
    "    \"JG1699\",  # GraphSAGE/CGR\n",
    "    \"JG1530\",  # XGB/FP+RDKit\n",
    "    \"JG1529\",  # XGB/FP\n",
    "    \"JG1531\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1527\",  # DMPNN/CGR\n",
    "    \"JG1528\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.7\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(tag, set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/0D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the same with a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = \"#4b4c68\"  # blue\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1697\",  # LogReg/FP\n",
    "    \"JG1700\",  # LogReg/RDKit\n",
    "    \"JG1698\",  # AttentiveFP/CGR\n",
    "    \"JG1699\",  # GraphSAGE/CGR\n",
    "    \"JG1530\",  # XGB/FP+RDKit\n",
    "    \"JG1529\",  # XGB/FP\n",
    "    \"JG1531\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1527\",  # DMPNN/CGR\n",
    "    \"JG1528\",  # FFN/OHE\n",
    "]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6,4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    color=fill_color,\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.7,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.875, 0.98))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the same with a data points only\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = \"#4b4c68\"  # blue\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1697\",  # LogReg/FP\n",
    "    \"JG1700\",  # LogReg/RDKit\n",
    "    \"JG1698\",  # AttentiveFP/CGR\n",
    "    \"JG1699\",  # GraphSAGE/CGR\n",
    "    \"JG1530\",  # XGB/FP+RDKit\n",
    "    \"JG1529\",  # XGB/FP\n",
    "    \"JG1531\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1527\",  # DMPNN/CGR\n",
    "    \"JG1528\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6,4))\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.7,\n",
    "             )\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.875, 0.98))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"FFN/OHE\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        wilcoxon_result = wilcoxon(x, y, alternative=\"two-sided\")\n",
    "        print(i, \":\\t\", wilcoxon_result, wilcoxon_result[1] < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (175/256, 87/256, 38/256)\n",
    "stroke_color = (132/256, 64/256, 30/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1701\",  # LogReg/FP\n",
    "    \"JG1702\",  # LogReg/RDKit\n",
    "    \"JG1708\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1704\",  # XGB/FP+RDKit\n",
    "    \"JG1703\",  # XGB/FP\n",
    "    \"JG1707\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1706\",  # DMPNN/CGR\n",
    "    \"JG1705\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (175/256, 87/256, 38/256)\n",
    "stroke_color = (132/256, 64/256, 30/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1701\",  # LogReg/FP\n",
    "    \"JG1702\",  # LogReg/RDKit\n",
    "    \"JG1708\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1704\",  # XGB/FP+RDKit\n",
    "    \"JG1703\",  # XGB/FP\n",
    "    \"JG1707\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1706\",  # DMPNN/CGR\n",
    "    \"JG1705\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.8,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.65, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (175/256, 87/256, 38/256)\n",
    "stroke_color = (132/256, 64/256, 30/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1701\",  # LogReg/FP\n",
    "    \"JG1702\",  # LogReg/RDKit\n",
    "    \"JG1708\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1704\",  # XGB/FP+RDKit\n",
    "    \"JG1703\",  # XGB/FP\n",
    "    \"JG1707\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1706\",  # DMPNN/CGR\n",
    "    \"JG1705\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.65, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"XGB/FP+RDKit\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        wilcoxon_result = wilcoxon(x, y, alternative=\"two-sided\")\n",
    "        print(i, \":\\t\", wilcoxon_result, wilcoxon_result[1] < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (249/256, 158/256, 35/256)\n",
    "stroke_color = (186/256, 115/256, 28/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1710\",  # LogReg/FP\n",
    "    \"JG1711\",  # LogReg/RDKit\n",
    "    \"JG1717\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1713\",  # XGB/FP+RDKit\n",
    "    \"JG1712\",  # XGB/FP\n",
    "    \"JG1716\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1715\",  # DMPNN/CGR\n",
    "    \"JG1714\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (249/256, 158/256, 35/256)\n",
    "stroke_color = (186/256, 115/256, 28/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1710\",  # LogReg/FP\n",
    "    \"JG1711\",  # LogReg/RDKit\n",
    "    \"JG1717\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1713\",  # XGB/FP+RDKit\n",
    "    \"JG1712\",  # XGB/FP\n",
    "    \"JG1716\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1715\",  # DMPNN/CGR\n",
    "    \"JG1714\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (249/256, 158/256, 35/256)\n",
    "stroke_color = (186/256, 115/256, 28/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1710\",  # LogReg/FP\n",
    "    \"JG1711\",  # LogReg/RDKit\n",
    "    \"JG1717\",  # AttentiveFP/CGR\n",
    "    \"JG1709\",  # GraphSAGE/CGR\n",
    "    \"JG1713\",  # XGB/FP+RDKit\n",
    "    \"JG1712\",  # XGB/FP\n",
    "    \"JG1716\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1715\",  # DMPNN/CGR\n",
    "    \"JG1714\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"D-MPNN/CGR\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        wilcoxon_result = wilcoxon(x, y, alternative=\"two-sided\")\n",
    "        print(i, \":\\t\", wilcoxon_result, wilcoxon_result[1] < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (123/256, 154/256, 207/256)\n",
    "stroke_color = (99/256, 126/256, 165/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1720\",  # LogReg/RDKit\n",
    "    \"JG1726\",  # AttentiveFP/CGR\n",
    "    \"JG1727\",  # GraphSAGE/CGR\n",
    "    \"JG1722\",  # XGB/FP+RDKit\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "    \"JG1723\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (123/256, 154/256, 207/256)\n",
    "stroke_color = (99/256, 126/256, 165/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1720\",  # LogReg/RDKit\n",
    "    \"JG1726\",  # AttentiveFP/CGR\n",
    "    \"JG1727\",  # GraphSAGE/CGR\n",
    "    \"JG1722\",  # XGB/FP+RDKit\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "    \"JG1723\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (123/256, 154/256, 207/256)\n",
    "stroke_color = (99/256, 126/256, 165/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1720\",  # LogReg/RDKit\n",
    "    \"JG1726\",  # AttentiveFP/CGR\n",
    "    \"JG1727\",  # GraphSAGE/CGR\n",
    "    \"JG1722\",  # XGB/FP+RDKit\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "    \"JG1723\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a lineplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1720\",  # LogReg/RDKit\n",
    "    \"JG1726\",  # AttentiveFP/CGR\n",
    "    \"JG1727\",  # GraphSAGE/CGR\n",
    "    \"JG1722\",  # XGB/FP+RDKit\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "    \"JG1723\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              hue=\"fold\", \n",
    "              palette=sns.color_palette(\"husl\", 9),\n",
    "              #edgecolor=stroke_color,\n",
    "              #color=fill_color,\n",
    "              #linewidth=.5,\n",
    "              #legend=False,\n",
    "              #marker=\"o\",\n",
    "              #size=3.5,\n",
    "              #alpha=.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same, but only best models\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              hue=\"fold\", \n",
    "              palette=sns.color_palette(\"husl\", 9),\n",
    "              #edgecolor=stroke_color,\n",
    "              #color=fill_color,\n",
    "              #linewidth=.5,\n",
    "              #legend=False,\n",
    "              #marker=\"o\",\n",
    "              #size=3.5,\n",
    "              #alpha=.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 0.95))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = [\n",
    "    \"JG1719\",  # LogReg/FP\n",
    "    \"JG1720\",  # LogReg/RDKit\n",
    "    \"JG1726\",  # AttentiveFP/CGR\n",
    "    \"JG1727\",  # GraphSAGE/CGR\n",
    "    \"JG1722\",  # XGB/FP+RDKit\n",
    "    \"JG1721\",  # XGB/FP\n",
    "    \"JG1725\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1724\",  # DMPNN/CGR\n",
    "    \"JG1723\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "\n",
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"LogisticRegression/FP\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        wilcoxon_result = wilcoxon(x, y, alternative=\"two-sided\")\n",
    "        print(i, \":\\t\", wilcoxon_result, wilcoxon_result[1] < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some settings for all following plots\n",
    "\n",
    "# order used for hue/style\n",
    "order = ['FFN/OHE', 'XGB/FP', 'XGB/FP+RDKit', 'D-MPNN/CGR', 'D-MPNN/RDKit']\n",
    "\n",
    "# linestyle\n",
    "dashes=[(3, 3), (3, 3), (1, 1), (3, 3), (1, 1)]\n",
    "\n",
    "# alternative palette where two colors are reused with less saturation to show derivative categories\n",
    "#palette = sns.color_palette([\"#5790fc\", \"#f89c20\", \"#a66611\", \"#a0228d\", \"#783b6e\"])  # works for colorblind\n",
    "palette = sns.color_palette([\"#5790fc\", \"#f89c20\", \"#a66611\", \"#e42536\", \"#a1212c\"])  # works for colorblind\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1562\",  # FFN/OHE\n",
    "            \"JG1563\",  # XGB/FP\n",
    "            \"JG1564\",  # XGB/FP+RDKit\n",
    "            \"JG1565\",  # D-MPNN/CGR\n",
    "            \"JG1566\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1557\",  # FFN/OHE\n",
    "            \"JG1558\",  # XGB/FP\n",
    "            \"JG1559\",  # XGB/FP+RDKit\n",
    "            \"JG1560\",  # D-MPNN/CGR\n",
    "            \"JG1561\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1552\",  # FFN/OHE\n",
    "            \"JG1553\",  # XGB/FP\n",
    "            \"JG1554\",  # XGB/FP+RDKit\n",
    "            \"JG1555\",  # D-MPNN/CGR\n",
    "            \"JG1556\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1547\",  # FFN/OHE\n",
    "            \"JG1548\",  # XGB/FP\n",
    "            \"JG1549\",  # XGB/FP+RDKit\n",
    "            \"JG1550\",  # D-MPNN/CGR\n",
    "            \"JG1551\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1542\",  # FFN/OHE\n",
    "            \"JG1543\",  # XGB/FP\n",
    "            \"JG1544\",  # XGB/FP+RDKit\n",
    "            \"JG1545\",  # D-MPNN/CGR\n",
    "            \"JG1546\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1537\",  # FFN/OHE\n",
    "            \"JG1538\",  # XGB/FP\n",
    "            \"JG1539\",  # XGB/FP+RDKit\n",
    "            \"JG1540\",  # D-MPNN/CGR\n",
    "            \"JG1541\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1532\",  # FFN/OHE\n",
    "            \"JG1533\",  # XGB/FP\n",
    "            \"JG1534\",  # XGB/FP+RDKit\n",
    "            \"JG1535\",  # D-MPNN/CGR\n",
    "            \"JG1536\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1528\",  # FFN/OHE\n",
    "            \"JG1529\",  # XGB/FP\n",
    "            \"JG1530\",  # XGB/FP+RDKit\n",
    "            \"JG1527\",  # D-MPNN/CGR\n",
    "            \"JG1531\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "# don't plot chance level b/c it is much lower\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax.set_ylim((0.75, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(title=None, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1562\",  # FFN/OHE\n",
    "            \"JG1563\",  # XGB/FP\n",
    "            \"JG1564\",  # XGB/FP+RDKit\n",
    "            \"JG1565\",  # D-MPNN/CGR\n",
    "            \"JG1566\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1557\",  # FFN/OHE\n",
    "            \"JG1558\",  # XGB/FP\n",
    "            \"JG1559\",  # XGB/FP+RDKit\n",
    "            \"JG1560\",  # D-MPNN/CGR\n",
    "            \"JG1561\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1552\",  # FFN/OHE\n",
    "            \"JG1553\",  # XGB/FP\n",
    "            \"JG1554\",  # XGB/FP+RDKit\n",
    "            \"JG1555\",  # D-MPNN/CGR\n",
    "            \"JG1556\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1547\",  # FFN/OHE\n",
    "            \"JG1548\",  # XGB/FP\n",
    "            \"JG1549\",  # XGB/FP+RDKit\n",
    "            \"JG1550\",  # D-MPNN/CGR\n",
    "            \"JG1551\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1542\",  # FFN/OHE\n",
    "            \"JG1543\",  # XGB/FP\n",
    "            \"JG1544\",  # XGB/FP+RDKit\n",
    "            \"JG1545\",  # D-MPNN/CGR\n",
    "            \"JG1546\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1537\",  # FFN/OHE\n",
    "            \"JG1538\",  # XGB/FP\n",
    "            \"JG1539\",  # XGB/FP+RDKit\n",
    "            \"JG1540\",  # D-MPNN/CGR\n",
    "            \"JG1541\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1532\",  # FFN/OHE\n",
    "            \"JG1533\",  # XGB/FP\n",
    "            \"JG1534\",  # XGB/FP+RDKit\n",
    "            \"JG1535\",  # D-MPNN/CGR\n",
    "            \"JG1536\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1528\",  # FFN/OHE\n",
    "            \"JG1529\",  # XGB/FP\n",
    "            \"JG1530\",  # XGB/FP+RDKit\n",
    "            \"JG1527\",  # D-MPNN/CGR\n",
    "            \"JG1531\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "# don't plot chance level b/c it is much lower\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax.set_ylim((0.75, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1562\",  # FFN/OHE\n",
    "            \"JG1563\",  # XGB/FP\n",
    "            \"JG1564\",  # XGB/FP+RDKit\n",
    "            \"JG1565\",  # D-MPNN/CGR\n",
    "            \"JG1566\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1557\",  # FFN/OHE\n",
    "            \"JG1558\",  # XGB/FP\n",
    "            \"JG1559\",  # XGB/FP+RDKit\n",
    "            \"JG1560\",  # D-MPNN/CGR\n",
    "            \"JG1561\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1552\",  # FFN/OHE\n",
    "            \"JG1553\",  # XGB/FP\n",
    "            \"JG1554\",  # XGB/FP+RDKit\n",
    "            \"JG1555\",  # D-MPNN/CGR\n",
    "            \"JG1556\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1547\",  # FFN/OHE\n",
    "            \"JG1548\",  # XGB/FP\n",
    "            \"JG1549\",  # XGB/FP+RDKit\n",
    "            \"JG1550\",  # D-MPNN/CGR\n",
    "            \"JG1551\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1542\",  # FFN/OHE\n",
    "            \"JG1543\",  # XGB/FP\n",
    "            \"JG1544\",  # XGB/FP+RDKit\n",
    "            \"JG1545\",  # D-MPNN/CGR\n",
    "            \"JG1546\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1537\",  # FFN/OHE\n",
    "            \"JG1538\",  # XGB/FP\n",
    "            \"JG1539\",  # XGB/FP+RDKit\n",
    "            \"JG1540\",  # D-MPNN/CGR\n",
    "            \"JG1541\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1532\",  # FFN/OHE\n",
    "            \"JG1533\",  # XGB/FP\n",
    "            \"JG1534\",  # XGB/FP+RDKit\n",
    "            \"JG1535\",  # D-MPNN/CGR\n",
    "            \"JG1536\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1528\",  # FFN/OHE\n",
    "            \"JG1529\",  # XGB/FP\n",
    "            \"JG1530\",  # XGB/FP+RDKit\n",
    "            \"JG1527\",  # D-MPNN/CGR\n",
    "            \"JG1531\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1592\",  # FFN/OHE\n",
    "            \"JG1593\",  # XGB/FP\n",
    "            \"JG1594\",  # XGB/FP+RDKit\n",
    "            \"JG1595\",  # D-MPNN/CGR\n",
    "            \"JG1596\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1587\",  # FFN/OHE\n",
    "            \"JG1588\",  # XGB/FP\n",
    "            \"JG1589\",  # XGB/FP+RDKit\n",
    "            \"JG1590\",  # D-MPNN/CGR\n",
    "            \"JG1591\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1582\",  # FFN/OHE\n",
    "            \"JG1583\",  # XGB/FP\n",
    "            \"JG1584\",  # XGB/FP+RDKit\n",
    "            \"JG1585\",  # D-MPNN/CGR\n",
    "            \"JG1586\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1577\",  # FFN/OHE\n",
    "            \"JG1578\",  # XGB/FP\n",
    "            \"JG1579\",  # XGB/FP+RDKit\n",
    "            \"JG1580\",  # D-MPNN/CGR\n",
    "            \"JG1581\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1572\",  # FFN/OHE\n",
    "            \"JG1573\",  # XGB/FP\n",
    "            \"JG1574\",  # XGB/FP+RDKit\n",
    "            \"JG1575\",  # D-MPNN/CGR\n",
    "            \"JG1576\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1567\",  # FFN/OHE\n",
    "            \"JG1568\",  # XGB/FP\n",
    "            \"JG1569\",  # XGB/FP+RDKit\n",
    "            \"JG1570\",  # D-MPNN/CGR\n",
    "            \"JG1571\",  # D-MPNN/CGR+RDKit\n",
    "    ], \n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.70, 0.95))\n",
    "ax.set_xticks(\n",
    "    [500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1592\",  # FFN/OHE\n",
    "            \"JG1593\",  # XGB/FP\n",
    "            \"JG1594\",  # XGB/FP+RDKit\n",
    "            \"JG1595\",  # D-MPNN/CGR\n",
    "            \"JG1596\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1587\",  # FFN/OHE\n",
    "            \"JG1588\",  # XGB/FP\n",
    "            \"JG1589\",  # XGB/FP+RDKit\n",
    "            \"JG1590\",  # D-MPNN/CGR\n",
    "            \"JG1591\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1582\",  # FFN/OHE\n",
    "            \"JG1583\",  # XGB/FP\n",
    "            \"JG1584\",  # XGB/FP+RDKit\n",
    "            \"JG1585\",  # D-MPNN/CGR\n",
    "            \"JG1586\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1577\",  # FFN/OHE\n",
    "            \"JG1578\",  # XGB/FP\n",
    "            \"JG1579\",  # XGB/FP+RDKit\n",
    "            \"JG1580\",  # D-MPNN/CGR\n",
    "            \"JG1581\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1572\",  # FFN/OHE\n",
    "            \"JG1573\",  # XGB/FP\n",
    "            \"JG1574\",  # XGB/FP+RDKit\n",
    "            \"JG1575\",  # D-MPNN/CGR\n",
    "            \"JG1576\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1567\",  # FFN/OHE\n",
    "            \"JG1568\",  # XGB/FP\n",
    "            \"JG1569\",  # XGB/FP+RDKit\n",
    "            \"JG1570\",  # D-MPNN/CGR\n",
    "            \"JG1571\",  # D-MPNN/CGR+RDKit\n",
    "    ], \n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.70, 0.95))\n",
    "ax.set_xticks(\n",
    "    [500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1592\",  # FFN/OHE\n",
    "            \"JG1593\",  # XGB/FP\n",
    "            \"JG1594\",  # XGB/FP+RDKit\n",
    "            \"JG1595\",  # D-MPNN/CGR\n",
    "            \"JG1596\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1587\",  # FFN/OHE\n",
    "            \"JG1588\",  # XGB/FP\n",
    "            \"JG1589\",  # XGB/FP+RDKit\n",
    "            \"JG1590\",  # D-MPNN/CGR\n",
    "            \"JG1591\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1582\",  # FFN/OHE\n",
    "            \"JG1583\",  # XGB/FP\n",
    "            \"JG1584\",  # XGB/FP+RDKit\n",
    "            \"JG1585\",  # D-MPNN/CGR\n",
    "            \"JG1586\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1577\",  # FFN/OHE\n",
    "            \"JG1578\",  # XGB/FP\n",
    "            \"JG1579\",  # XGB/FP+RDKit\n",
    "            \"JG1580\",  # D-MPNN/CGR\n",
    "            \"JG1581\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1572\",  # FFN/OHE\n",
    "            \"JG1573\",  # XGB/FP\n",
    "            \"JG1574\",  # XGB/FP+RDKit\n",
    "            \"JG1575\",  # D-MPNN/CGR\n",
    "            \"JG1576\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1567\",  # FFN/OHE\n",
    "            \"JG1568\",  # XGB/FP\n",
    "            \"JG1569\",  # XGB/FP+RDKit\n",
    "            \"JG1570\",  # D-MPNN/CGR\n",
    "            \"JG1571\",  # D-MPNN/CGR+RDKit\n",
    "    ], \n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5\n",
    "            \"JG1637\",  # FFN/OHE\n",
    "            \"JG1638\",  # XGB/FP\n",
    "            \"JG1639\",  # XGB/FP+RDKit\n",
    "            \"JG1640\",  # D-MPNN/CGR\n",
    "            \"JG1641\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1632\",  # FFN/OHE\n",
    "            \"JG1633\",  # XGB/FP\n",
    "            \"JG1634\",  # XGB/FP+RDKit\n",
    "            \"JG1635\",  # D-MPNN/CGR\n",
    "            \"JG1636\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1627\",  # FFN/OHE\n",
    "            \"JG1628\",  # XGB/FP\n",
    "            \"JG1629\",  # XGB/FP+RDKit\n",
    "            \"JG1630\",  # D-MPNN/CGR\n",
    "            \"JG1631\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1622\",  # FFN/OHE\n",
    "            \"JG1623\",  # XGB/FP\n",
    "            \"JG1624\",  # XGB/FP+RDKit\n",
    "            \"JG1625\",  # D-MPNN/CGR\n",
    "            \"JG1626\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1617\",  # FFN/OHE\n",
    "            \"JG1618\",  # XGB/FP\n",
    "            \"JG1619\",  # XGB/FP+RDKit\n",
    "            \"JG1620\",  # D-MPNN/CGR\n",
    "            \"JG1621\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1612\",  # FFN/OHE\n",
    "            \"JG1613\",  # XGB/FP\n",
    "            \"JG1614\",  # XGB/FP+RDKit\n",
    "            \"JG1615\",  # D-MPNN/CGR\n",
    "            \"JG1616\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1607\",  # FFN/OHE\n",
    "            \"JG1608\",  # XGB/FP\n",
    "            \"JG1609\",  # XGB/FP+RDKit\n",
    "            \"JG1610\",  # D-MPNN/CGR\n",
    "            \"JG1611\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1602\",  # FFN/OHE\n",
    "            \"JG1603\",  # XGB/FP\n",
    "            \"JG1604\",  # XGB/FP+RDKit\n",
    "            \"JG1605\",  # D-MPNN/CGR\n",
    "            \"JG1606\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1597\",  # FFN/OHE\n",
    "            \"JG1598\",  # XGB/FP\n",
    "            \"JG1599\",  # XGB/FP+RDKit\n",
    "            \"JG1600\",  # D-MPNN/CGR\n",
    "            \"JG1601\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.53, 0.9))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5\n",
    "            \"JG1637\",  # FFN/OHE\n",
    "            \"JG1638\",  # XGB/FP\n",
    "            \"JG1639\",  # XGB/FP+RDKit\n",
    "            \"JG1640\",  # D-MPNN/CGR\n",
    "            \"JG1641\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1632\",  # FFN/OHE\n",
    "            \"JG1633\",  # XGB/FP\n",
    "            \"JG1634\",  # XGB/FP+RDKit\n",
    "            \"JG1635\",  # D-MPNN/CGR\n",
    "            \"JG1636\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1627\",  # FFN/OHE\n",
    "            \"JG1628\",  # XGB/FP\n",
    "            \"JG1629\",  # XGB/FP+RDKit\n",
    "            \"JG1630\",  # D-MPNN/CGR\n",
    "            \"JG1631\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1622\",  # FFN/OHE\n",
    "            \"JG1623\",  # XGB/FP\n",
    "            \"JG1624\",  # XGB/FP+RDKit\n",
    "            \"JG1625\",  # D-MPNN/CGR\n",
    "            \"JG1626\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1617\",  # FFN/OHE\n",
    "            \"JG1618\",  # XGB/FP\n",
    "            \"JG1619\",  # XGB/FP+RDKit\n",
    "            \"JG1620\",  # D-MPNN/CGR\n",
    "            \"JG1621\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1612\",  # FFN/OHE\n",
    "            \"JG1613\",  # XGB/FP\n",
    "            \"JG1614\",  # XGB/FP+RDKit\n",
    "            \"JG1615\",  # D-MPNN/CGR\n",
    "            \"JG1616\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1607\",  # FFN/OHE\n",
    "            \"JG1608\",  # XGB/FP\n",
    "            \"JG1609\",  # XGB/FP+RDKit\n",
    "            \"JG1610\",  # D-MPNN/CGR\n",
    "            \"JG1611\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1602\",  # FFN/OHE\n",
    "            \"JG1603\",  # XGB/FP\n",
    "            \"JG1604\",  # XGB/FP+RDKit\n",
    "            \"JG1605\",  # D-MPNN/CGR\n",
    "            \"JG1606\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1597\",  # FFN/OHE\n",
    "            \"JG1598\",  # XGB/FP\n",
    "            \"JG1599\",  # XGB/FP+RDKit\n",
    "            \"JG1600\",  # D-MPNN/CGR\n",
    "            \"JG1601\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.9))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5 leave out due to excess variance\n",
    "#            \"JG1637\",  # FFN/OHE\n",
    "#            \"JG1638\",  # XGB/FP\n",
    "#            \"JG1639\",  # XGB/FP+RDKit\n",
    "#            \"JG1640\",  # D-MPNN/CGR\n",
    "#            \"JG1641\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1632\",  # FFN/OHE\n",
    "            \"JG1633\",  # XGB/FP\n",
    "            \"JG1634\",  # XGB/FP+RDKit\n",
    "            \"JG1635\",  # D-MPNN/CGR\n",
    "            \"JG1636\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1627\",  # FFN/OHE\n",
    "            \"JG1628\",  # XGB/FP\n",
    "            \"JG1629\",  # XGB/FP+RDKit\n",
    "            \"JG1630\",  # D-MPNN/CGR\n",
    "            \"JG1631\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1622\",  # FFN/OHE\n",
    "            \"JG1623\",  # XGB/FP\n",
    "            \"JG1624\",  # XGB/FP+RDKit\n",
    "            \"JG1625\",  # D-MPNN/CGR\n",
    "            \"JG1626\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1617\",  # FFN/OHE\n",
    "            \"JG1618\",  # XGB/FP\n",
    "            \"JG1619\",  # XGB/FP+RDKit\n",
    "            \"JG1620\",  # D-MPNN/CGR\n",
    "            \"JG1621\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1612\",  # FFN/OHE\n",
    "            \"JG1613\",  # XGB/FP\n",
    "            \"JG1614\",  # XGB/FP+RDKit\n",
    "            \"JG1615\",  # D-MPNN/CGR\n",
    "            \"JG1616\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1607\",  # FFN/OHE\n",
    "            \"JG1608\",  # XGB/FP\n",
    "            \"JG1609\",  # XGB/FP+RDKit\n",
    "            \"JG1610\",  # D-MPNN/CGR\n",
    "            \"JG1611\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1602\",  # FFN/OHE\n",
    "            \"JG1603\",  # XGB/FP\n",
    "            \"JG1604\",  # XGB/FP+RDKit\n",
    "            \"JG1605\",  # D-MPNN/CGR\n",
    "            \"JG1606\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1597\",  # FFN/OHE\n",
    "            \"JG1598\",  # XGB/FP\n",
    "            \"JG1599\",  # XGB/FP+RDKit\n",
    "            \"JG1600\",  # D-MPNN/CGR\n",
    "            \"JG1601\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(9)], \n",
    "    [f\"{125*2**n}\" for n in range(9)],\n",
    ")\n",
    "legend = ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1692\",  # FFN/OHE\n",
    "            \"JG1693\",  # XGB/FP\n",
    "            \"JG1694\",  # XGB/FP+RDKit\n",
    "            \"JG1695\",  # D-MPNN/CGR\n",
    "            \"JG1696\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1687\",  # FFN/OHE\n",
    "            \"JG1688\",  # XGB/FP\n",
    "            \"JG1689\",  # XGB/FP+RDKit\n",
    "            \"JG1690\",  # D-MPNN/CGR\n",
    "            \"JG1691\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1682\",  # FFN/OHE\n",
    "            \"JG1683\",  # XGB/FP\n",
    "            \"JG1684\",  # XGB/FP+RDKit\n",
    "            \"JG1685\",  # D-MPNN/CGR\n",
    "            \"JG1686\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1677\",  # FFN/OHE\n",
    "            \"JG1678\",  # XGB/FP\n",
    "            \"JG1679\",  # XGB/FP+RDKit\n",
    "            \"JG1680\",  # D-MPNN/CGR\n",
    "            \"JG1681\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1672\",  # FFN/OHE\n",
    "            \"JG1673\",  # XGB/FP\n",
    "            \"JG1674\",  # XGB/FP+RDKit\n",
    "            \"JG1675\",  # D-MPNN/CGR\n",
    "            \"JG1676\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1667\",  # FFN/OHE\n",
    "            \"JG1668\",  # XGB/FP\n",
    "            \"JG1669\",  # XGB/FP+RDKit\n",
    "            \"JG1670\",  # D-MPNN/CGR\n",
    "            \"JG1671\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1662\",  # FFN/OHE\n",
    "            \"JG1663\",  # XGB/FP\n",
    "            \"JG1664\",  # XGB/FP+RDKit\n",
    "            \"JG1665\",  # D-MPNN/CGR\n",
    "            \"JG1666\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1657\",  # FFN/OHE\n",
    "            \"JG1658\",  # XGB/FP\n",
    "            \"JG1659\",  # XGB/FP+RDKit\n",
    "            \"JG1660\",  # D-MPNN/CGR\n",
    "            \"JG1661\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1652\",  # FFN/OHE\n",
    "            \"JG1653\",  # XGB/FP\n",
    "            \"JG1654\",  # XGB/FP+RDKit\n",
    "            \"JG1655\",  # D-MPNN/CGR\n",
    "            \"JG1656\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1647\",  # FFN/OHE\n",
    "            \"JG1648\",  # XGB/FP\n",
    "            \"JG1649\",  # XGB/FP+RDKit\n",
    "            \"JG1650\",  # D-MPNN/CGR\n",
    "            \"JG1651\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1642\",  # FFN/OHE\n",
    "            \"JG1643\",  # XGB/FP\n",
    "            \"JG1644\",  # XGB/FP+RDKit\n",
    "            \"JG1645\",  # D-MPNN/CGR\n",
    "            \"JG1646\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\", \"3D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.9))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1692\",  # FFN/OHE\n",
    "            \"JG1693\",  # XGB/FP\n",
    "            \"JG1694\",  # XGB/FP+RDKit\n",
    "            \"JG1695\",  # D-MPNN/CGR\n",
    "            \"JG1696\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1687\",  # FFN/OHE\n",
    "            \"JG1688\",  # XGB/FP\n",
    "            \"JG1689\",  # XGB/FP+RDKit\n",
    "            \"JG1690\",  # D-MPNN/CGR\n",
    "            \"JG1691\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1682\",  # FFN/OHE\n",
    "            \"JG1683\",  # XGB/FP\n",
    "            \"JG1684\",  # XGB/FP+RDKit\n",
    "            \"JG1685\",  # D-MPNN/CGR\n",
    "            \"JG1686\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1677\",  # FFN/OHE\n",
    "            \"JG1678\",  # XGB/FP\n",
    "            \"JG1679\",  # XGB/FP+RDKit\n",
    "            \"JG1680\",  # D-MPNN/CGR\n",
    "            \"JG1681\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1672\",  # FFN/OHE\n",
    "            \"JG1673\",  # XGB/FP\n",
    "            \"JG1674\",  # XGB/FP+RDKit\n",
    "            \"JG1675\",  # D-MPNN/CGR\n",
    "            \"JG1676\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1667\",  # FFN/OHE\n",
    "            \"JG1668\",  # XGB/FP\n",
    "            \"JG1669\",  # XGB/FP+RDKit\n",
    "            \"JG1670\",  # D-MPNN/CGR\n",
    "            \"JG1671\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1662\",  # FFN/OHE\n",
    "            \"JG1663\",  # XGB/FP\n",
    "            \"JG1664\",  # XGB/FP+RDKit\n",
    "            \"JG1665\",  # D-MPNN/CGR\n",
    "            \"JG1666\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1657\",  # FFN/OHE\n",
    "            \"JG1658\",  # XGB/FP\n",
    "            \"JG1659\",  # XGB/FP+RDKit\n",
    "            \"JG1660\",  # D-MPNN/CGR\n",
    "            \"JG1661\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1652\",  # FFN/OHE\n",
    "            \"JG1653\",  # XGB/FP\n",
    "            \"JG1654\",  # XGB/FP+RDKit\n",
    "            \"JG1655\",  # D-MPNN/CGR\n",
    "            \"JG1656\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1647\",  # FFN/OHE\n",
    "            \"JG1648\",  # XGB/FP\n",
    "            \"JG1649\",  # XGB/FP+RDKit\n",
    "            \"JG1650\",  # D-MPNN/CGR\n",
    "            \"JG1651\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1642\",  # FFN/OHE\n",
    "            \"JG1643\",  # XGB/FP\n",
    "            \"JG1644\",  # XGB/FP+RDKit\n",
    "            \"JG1645\",  # D-MPNN/CGR\n",
    "            \"JG1646\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\", \"3D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    dashes=dashes,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.85))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition of the last plot, but with number of seen building blocks on the x axis instead of training samples\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1692\",  # FFN/OHE\n",
    "            \"JG1693\",  # XGB/FP\n",
    "            \"JG1694\",  # XGB/FP+RDKit\n",
    "            \"JG1695\",  # D-MPNN/CGR\n",
    "            \"JG1696\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1687\",  # FFN/OHE\n",
    "            \"JG1688\",  # XGB/FP\n",
    "            \"JG1689\",  # XGB/FP+RDKit\n",
    "            \"JG1690\",  # D-MPNN/CGR\n",
    "            \"JG1691\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1682\",  # FFN/OHE\n",
    "            \"JG1683\",  # XGB/FP\n",
    "            \"JG1684\",  # XGB/FP+RDKit\n",
    "            \"JG1685\",  # D-MPNN/CGR\n",
    "            \"JG1686\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1677\",  # FFN/OHE\n",
    "            \"JG1678\",  # XGB/FP\n",
    "            \"JG1679\",  # XGB/FP+RDKit\n",
    "            \"JG1680\",  # D-MPNN/CGR\n",
    "            \"JG1681\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1672\",  # FFN/OHE\n",
    "            \"JG1673\",  # XGB/FP\n",
    "            \"JG1674\",  # XGB/FP+RDKit\n",
    "            \"JG1675\",  # D-MPNN/CGR\n",
    "            \"JG1676\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1667\",  # FFN/OHE\n",
    "            \"JG1668\",  # XGB/FP\n",
    "            \"JG1669\",  # XGB/FP+RDKit\n",
    "            \"JG1670\",  # D-MPNN/CGR\n",
    "            \"JG1671\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1662\",  # FFN/OHE\n",
    "            \"JG1663\",  # XGB/FP\n",
    "            \"JG1664\",  # XGB/FP+RDKit\n",
    "            \"JG1665\",  # D-MPNN/CGR\n",
    "            \"JG1666\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1657\",  # FFN/OHE\n",
    "            \"JG1658\",  # XGB/FP\n",
    "            \"JG1659\",  # XGB/FP+RDKit\n",
    "            \"JG1660\",  # D-MPNN/CGR\n",
    "            \"JG1661\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1652\",  # FFN/OHE\n",
    "            \"JG1653\",  # XGB/FP\n",
    "            \"JG1654\",  # XGB/FP+RDKit\n",
    "            \"JG1655\",  # D-MPNN/CGR\n",
    "            \"JG1656\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1647\",  # FFN/OHE\n",
    "            \"JG1648\",  # XGB/FP\n",
    "            \"JG1649\",  # XGB/FP+RDKit\n",
    "            \"JG1650\",  # D-MPNN/CGR\n",
    "            \"JG1651\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1642\",  # FFN/OHE\n",
    "            \"JG1643\",  # XGB/FP\n",
    "            \"JG1644\",  # XGB/FP+RDKit\n",
    "            \"JG1645\",  # D-MPNN/CGR\n",
    "            \"JG1646\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_buildingblock_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\", \"3D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    dashes=dashes,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data unique building blocks\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "#ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.85))\n",
    "#ax.set_xticks(\n",
    "#    [32*2**n for n in range(10)], \n",
    "#    [f\"{32*2**n}\" for n in range(10)],\n",
    "#)\n",
    "ax.legend(loc=\"center right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "\n",
    "experiment_ids = [        \n",
    "#       [  # _10  # do not plot b/c excessive variance\n",
    "#           \"JG1692\",  # FFN/OHE\n",
    "#           \"JG1693\",  # XGB/FP\n",
    "#           \"JG1694\",  # XGB/FP+RDKit\n",
    "#           \"JG1695\",  # D-MPNN/CGR\n",
    "#           \"JG1696\",  # D-MPNN/CGR+RDKit\n",
    "#   ],\n",
    "        [  # _15\n",
    "            \"JG1687\",  # FFN/OHE\n",
    "            \"JG1688\",  # XGB/FP\n",
    "            \"JG1689\",  # XGB/FP+RDKit\n",
    "            \"JG1690\",  # D-MPNN/CGR\n",
    "            \"JG1691\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1682\",  # FFN/OHE\n",
    "            \"JG1683\",  # XGB/FP\n",
    "            \"JG1684\",  # XGB/FP+RDKit\n",
    "            \"JG1685\",  # D-MPNN/CGR\n",
    "            \"JG1686\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1677\",  # FFN/OHE\n",
    "            \"JG1678\",  # XGB/FP\n",
    "            \"JG1679\",  # XGB/FP+RDKit\n",
    "            \"JG1680\",  # D-MPNN/CGR\n",
    "            \"JG1681\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1672\",  # FFN/OHE\n",
    "            \"JG1673\",  # XGB/FP\n",
    "            \"JG1674\",  # XGB/FP+RDKit\n",
    "            \"JG1675\",  # D-MPNN/CGR\n",
    "            \"JG1676\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1667\",  # FFN/OHE\n",
    "            \"JG1668\",  # XGB/FP\n",
    "            \"JG1669\",  # XGB/FP+RDKit\n",
    "            \"JG1670\",  # D-MPNN/CGR\n",
    "            \"JG1671\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1662\",  # FFN/OHE\n",
    "            \"JG1663\",  # XGB/FP\n",
    "            \"JG1664\",  # XGB/FP+RDKit\n",
    "            \"JG1665\",  # D-MPNN/CGR\n",
    "            \"JG1666\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1657\",  # FFN/OHE\n",
    "            \"JG1658\",  # XGB/FP\n",
    "            \"JG1659\",  # XGB/FP+RDKit\n",
    "            \"JG1660\",  # D-MPNN/CGR\n",
    "            \"JG1661\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1652\",  # FFN/OHE\n",
    "            \"JG1653\",  # XGB/FP\n",
    "            \"JG1654\",  # XGB/FP+RDKit\n",
    "            \"JG1655\",  # D-MPNN/CGR\n",
    "            \"JG1656\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1647\",  # FFN/OHE\n",
    "            \"JG1648\",  # XGB/FP\n",
    "            \"JG1649\",  # XGB/FP+RDKit\n",
    "            \"JG1650\",  # D-MPNN/CGR\n",
    "            \"JG1651\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1642\",  # FFN/OHE\n",
    "            \"JG1643\",  # XGB/FP\n",
    "            \"JG1644\",  # XGB/FP+RDKit\n",
    "            \"JG1645\",  # D-MPNN/CGR\n",
    "            \"JG1646\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\", \"3D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1.))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(9)], \n",
    "    [f\"{125*2**n}\" for n in range(9)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
