{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot model performance\n",
    "\n",
    "Visualize performance on different models on data `2023-12-20` from the wandb API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path(\"__file__\").absolute().parents[1]))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import wilcoxon\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "\n",
    "from utils import BodeColorPalette, get_runs_as_list\n",
    "from src.util.definitions import DATA_ROOT\n",
    "bode_palette = BodeColorPalette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "sns.set_theme(context=\"paper\", \n",
    "              style=\"white\", \n",
    "              font_scale=1, #0.7,\n",
    "              rc={\"savefig.transparent\": True, \n",
    "                  \"axes.grid\": False, \n",
    "                  \"axes.spines.bottom\": True,\n",
    "                  \"axes.spines.left\": False,\n",
    "                  \"axes.spines.right\": False,\n",
    "                  \"axes.spines.top\": False,\n",
    "                  \"font.family\":'sans-serif',\n",
    "                  \"font.sans-serif\":[\"Helvetica\", \"Arial\"],\n",
    "                  \"xtick.major.pad\": 0.0,\n",
    "                  \"xtick.minor.pad\": 0.0,\n",
    "                  \"ytick.major.pad\": 0.0,\n",
    "                  \"ytick.minor.pad\": 0.0,\n",
    "                  \"axes.labelweight\": \"bold\",\n",
    "                  \"axes.labelpad\": 2.5,  # standard is 4.0\n",
    "                  \"axes.xmargin\": .05,\n",
    "                 }, \n",
    "             )\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 6,\n",
    "    'axes.titlesize': 6,\n",
    "    'xtick.labelsize': 6,\n",
    "    'ytick.labelsize': 6,\n",
    "    'legend.fontsize': 6,\n",
    "    'font.size': 6,\n",
    "    'svg.fonttype': 'none',  # necessary to have editable text in SVGs\n",
    "    'text.color': 'black',\n",
    "    'axes.labelcolor': 'black',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "# more settings for all plots\n",
    "errorbar = \"se\"  # standard error of the mean\n",
    "errwidth = .9\n",
    "errcolor = \"black\"\n",
    "capsize = .1  # size of the end of the errorbar\n",
    "linewidth = 1.  # width of the outline of barplot\n",
    "\n",
    "palette = [\n",
    "    bode_palette.blues[0], \n",
    "    bode_palette.oranges[0],\n",
    "    bode_palette.blues[2],\n",
    "    bode_palette.oranges[2],\n",
    "    bode_palette.blues[3],\n",
    "    bode_palette.oranges[3]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get data from wandb API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list, config_list, tag_list, name_list  = get_runs_as_list(filters={\"$or\":\n",
    "                                                             [{\"jobType\": \"training\"},\n",
    "                                                              {\"jobType\": \"hparam_best\"}\n",
    "                                                             ]})\n",
    "df_all = pd.json_normalize(config_list).merge(pd.json_normalize(summary_list), left_index=True, right_index=True)\n",
    "df_all[\"tags\"] = tag_list\n",
    "df_all[\"run_id\"] = name_list\n",
    "df_all[\"run_group\"] = [s.rsplit(\"_\", maxsplit=1)[0] for s in name_list]\n",
    "df_all[\"Model+Features\"] = df_all[\"name\"] + \"/\" + df_all[\"decoder.global_features\"].str.join(\"+\").str.replace(\"None\", \"CGR\")\n",
    "df_all[\"fold\"] = df_all[\"run_id\"].str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"experiment_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for relevant data (JG1309 onwards for 2023-12-20 models)\n",
    "df_all = df_all.loc[df_all[\"experiment_id\"].apply(lambda x: int(x.strip(\"JG\")) > 1308 if isinstance(x, str) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available experiments by split\n",
    "for tag, row in df_all.groupby(\"tags\")[[\"experiment_id\"]].agg(set).iterrows():\n",
    "    print(tag, \"-->\", row[\"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dir where we will save plots\n",
    "analysis_dir = pathlib.Path(\"results\")\n",
    "# set date (of the dataset) for saving\n",
    "datadate = \"2023-12-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stats = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "\n",
    "def get_chance_ap(split_name, fold=None, set_type=\"test\"):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    if fold is not None:\n",
    "        return df.loc[(df[\"split_name\"] == split_name ) & (df[\"fold\"] == fold), f\"Chance level average precision macro on {set_type} set\"].item()\n",
    "    else:\n",
    "        return df.loc[(df[\"split_name\"] == split_name ), f\"Chance level average precision macro on {set_type} set\"].mean()\n",
    "    \n",
    "def get_sample_count(split_name, fold=None):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    if fold is not None:\n",
    "        return int(df.loc[(df[\"split_name\"] == split_name) & (df[\"fold\"] == fold), \"Train samples\"].item().split()[0])\n",
    "    else:\n",
    "        return int(df.loc[df[\"split_name\"] == split_name, \"Train samples\"].str.split(expand=True)[0].astype(\"int\").mean())    \n",
    "    \n",
    "        \n",
    "def get_buildingblock_count(split_name, fold=None, bb_types=[\"initiators\", \"monomers\", \"terminators\"]):\n",
    "    df = pd.read_csv(DATA_ROOT / \"splits\" / f\"split_statistics_{datadate}.csv\")\n",
    "    for s in bb_types:\n",
    "        if s not in [\"initiators\", \"monomers\", \"terminators\"]:  # catch incorrect options for bulding blocks\n",
    "            raise ValueError(\"This building block type does not exist\")\n",
    "    columns = [f\"Train {s}\" for s in bb_types]\n",
    "    if fold is not None:\n",
    "        return df.loc[(df[\"split_name\"] == split_name) & (df[\"fold\"] == fold), columns].mean(axis=None)\n",
    "    else:\n",
    "        return df.loc[df[\"split_name\"] == split_name, columns].mean(axis=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = '0.4'  # grey\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1480\",  # LogReg/FP\n",
    "    \"JG1483\",  # LogReg/RDKit\n",
    "    \"JG1481\",  # AttentiveFP/CGR\n",
    "    \"JG1482\",  # GraphSAGE/CGR\n",
    "    \"JG1311\",  # XGB/FP+RDKit\n",
    "    \"JG1310\",  # XGB/FP\n",
    "    \"JG1313\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1312\",  # DMPNN/CGR\n",
    "    \"JG1309\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(tag, set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/0D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the same with a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = '0.6'  # grey\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1480\",  # LogReg/FP\n",
    "    \"JG1483\",  # LogReg/RDKit\n",
    "    \"JG1481\",  # AttentiveFP/CGR\n",
    "    \"JG1482\",  # GraphSAGE/CGR\n",
    "    \"JG1311\",  # XGB/FP+RDKit\n",
    "    \"JG1310\",  # XGB/FP\n",
    "    \"JG1313\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1312\",  # DMPNN/CGR\n",
    "    \"JG1309\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6,4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    color=fill_color,\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.875, 0.975))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the same with a data points only\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"0D_80\"\n",
    "# choose the colorscheme\n",
    "fill_color = '0.4'  # grey\n",
    "stroke_color = '0.1'  # almost black\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1480\",  # LogReg/FP\n",
    "    \"JG1483\",  # LogReg/RDKit\n",
    "    \"JG1481\",  # AttentiveFP/CGR\n",
    "    \"JG1482\",  # GraphSAGE/CGR\n",
    "    \"JG1311\",  # XGB/FP+RDKit\n",
    "    \"JG1310\",  # XGB/FP\n",
    "    \"JG1313\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1312\",  # DMPNN/CGR\n",
    "    \"JG1309\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6,4))\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.9, 0.975))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"FFN/OHE\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        print(i, \":\\t\", wilcoxon(x, y, alternative=\"two-sided\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (189/256, 87/256, 213/256)\n",
    "stroke_color = (140/256, 67/256, 158/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1484\",  # LogReg/FP\n",
    "    \"JG1485\",  # LogReg/RDKit\n",
    "    \"JG1491\",  # AttentiveFP/CGR\n",
    "    \"JG1492\",  # GraphSAGE/CGR\n",
    "    \"JG1487\",  # XGB/FP+RDKit\n",
    "    \"JG1486\",  # XGB/FP\n",
    "    \"JG1490\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1489\",  # DMPNN/CGR\n",
    "    \"JG1488\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (189/256, 87/256, 213/256)\n",
    "stroke_color = (140/256, 67/256, 158/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1484\",  # LogReg/FP\n",
    "    \"JG1485\",  # LogReg/RDKit\n",
    "    \"JG1491\",  # AttentiveFP/CGR\n",
    "    \"JG1492\",  # GraphSAGE/CGR\n",
    "    \"JG1487\",  # XGB/FP+RDKit\n",
    "    \"JG1486\",  # XGB/FP\n",
    "    \"JG1490\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1489\",  # DMPNN/CGR\n",
    "    \"JG1488\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.65, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"1D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (189/256, 87/256, 213/256)\n",
    "stroke_color = (140/256, 67/256, 158/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1484\",  # LogReg/FP\n",
    "    \"JG1485\",  # LogReg/RDKit\n",
    "    \"JG1491\",  # AttentiveFP/CGR\n",
    "    \"JG1492\",  # GraphSAGE/CGR\n",
    "    \"JG1487\",  # XGB/FP+RDKit\n",
    "    \"JG1486\",  # XGB/FP\n",
    "    \"JG1490\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1489\",  # DMPNN/CGR\n",
    "    \"JG1488\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"1D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/1D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.65, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"XGB/FP+RDKit\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        print(i, \":\\t\", wilcoxon(x, y, alternative=\"two-sided\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (\n",
    "    135/256,\n",
    "    186/256,\n",
    "    112/256,\n",
    ")\n",
    "\n",
    "stroke_color = (92/256, 124/256, 76/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1493\",  # LogReg/FP\n",
    "    \"JG1494\",  # LogReg/RDKit\n",
    "    \"JG1500\",  # AttentiveFP/CGR\n",
    "    \"JG1501\",  # GraphSAGE/CGR\n",
    "    \"JG1496\",  # XGB/FP+RDKit\n",
    "    \"JG1495\",  # XGB/FP\n",
    "    \"JG1499\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1498\",  # DMPNN/CGR\n",
    "    \"JG1497\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (\n",
    "    135/256,\n",
    "    186/256,\n",
    "    112/256,\n",
    ")\n",
    "\n",
    "stroke_color = (92/256, 124/256, 76/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1493\",  # LogReg/FP\n",
    "    \"JG1494\",  # LogReg/RDKit\n",
    "    \"JG1500\",  # AttentiveFP/CGR\n",
    "    \"JG1501\",  # GraphSAGE/CGR\n",
    "    \"JG1496\",  # XGB/FP+RDKit\n",
    "    \"JG1495\",  # XGB/FP\n",
    "    \"JG1499\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1498\",  # DMPNN/CGR\n",
    "    \"JG1497\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"2D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (\n",
    "    135/256,\n",
    "    186/256,\n",
    "    112/256,\n",
    ")\n",
    "\n",
    "stroke_color = (92/256, 124/256, 76/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1493\",  # LogReg/FP\n",
    "    \"JG1494\",  # LogReg/RDKit\n",
    "    \"JG1500\",  # AttentiveFP/CGR\n",
    "    \"JG1501\",  # GraphSAGE/CGR\n",
    "    \"JG1496\",  # XGB/FP+RDKit\n",
    "    \"JG1495\",  # XGB/FP\n",
    "    \"JG1499\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1498\",  # DMPNN/CGR\n",
    "    \"JG1497\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"2D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/2D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.45, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"XGB/FP+RDKit\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        print(i, \":\\t\", wilcoxon(x, y, alternative=\"two-sided\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1502\",  # LogReg/FP\n",
    "    \"JG1503\",  # LogReg/RDKit\n",
    "    \"JG1509\",  # AttentiveFP/CGR\n",
    "    \"JG1510\",  # GraphSAGE/CGR\n",
    "    \"JG1505\",  # XGB/FP+RDKit\n",
    "    \"JG1504\",  # XGB/FP\n",
    "    \"JG1508\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1507\",  # DMPNN/CGR\n",
    "    \"JG1506\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(2.8,2))\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    errorbar=errorbar,\n",
    "    errwidth=errwidth,\n",
    "    errcolor=errcolor,\n",
    "    capsize=capsize,\n",
    "    color=fill_color,\n",
    "    edgecolor=stroke_color,\n",
    "    linewidth=linewidth,\n",
    "    alpha=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=2.5,\n",
    "              alpha=.8\n",
    "             )\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_barplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1502\",  # LogReg/FP\n",
    "    \"JG1503\",  # LogReg/RDKit\n",
    "    \"JG1509\",  # AttentiveFP/CGR\n",
    "    \"JG1510\",  # GraphSAGE/CGR\n",
    "    \"JG1505\",  # XGB/FP+RDKit\n",
    "    \"JG1504\",  # XGB/FP\n",
    "    \"JG1508\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1507\",  # DMPNN/CGR\n",
    "    \"JG1506\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "    x=\"Model+Features\",\n",
    "    y=metric,\n",
    "    color=fill_color,\n",
    "    boxprops={\"edgecolor\": stroke_color},\n",
    "    medianprops={\"color\": stroke_color},\n",
    "    linewidth=linewidth,\n",
    "    fliersize=2.5,\n",
    "    saturation=.8,\n",
    "    width=.7,\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.4, 0.9))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_boxplot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1502\",  # LogReg/FP\n",
    "    \"JG1503\",  # LogReg/RDKit\n",
    "    \"JG1509\",  # AttentiveFP/CGR\n",
    "    \"JG1510\",  # GraphSAGE/CGR\n",
    "    \"JG1505\",  # XGB/FP+RDKit\n",
    "    \"JG1504\",  # XGB/FP\n",
    "    \"JG1508\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1507\",  # DMPNN/CGR\n",
    "    \"JG1506\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.stripplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              dodge=True,\n",
    "              jitter=.15,\n",
    "              edgecolor=stroke_color,\n",
    "              color=fill_color,\n",
    "              linewidth=.5,\n",
    "              legend=False,\n",
    "              marker=\"o\",\n",
    "              size=3.5,\n",
    "              alpha=.8\n",
    ")\n",
    "\n",
    "ax.axhline(get_chance_ap(\"3D\", set_type=\"val\"), ls=\"--\", color=\"black\", linewidth=.7)  # chance level for val/3D\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.4, 0.9))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a lineplot\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1502\",  # LogReg/FP\n",
    "    \"JG1503\",  # LogReg/RDKit\n",
    "    \"JG1509\",  # AttentiveFP/CGR\n",
    "    \"JG1510\",  # GraphSAGE/CGR\n",
    "    \"JG1505\",  # XGB/FP+RDKit\n",
    "    \"JG1504\",  # XGB/FP\n",
    "    \"JG1508\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1507\",  # DMPNN/CGR\n",
    "    \"JG1506\",  # FFN/OHE\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              hue=\"fold\", \n",
    "              palette=sns.color_palette(\"husl\", 9),\n",
    "              #edgecolor=stroke_color,\n",
    "              #color=fill_color,\n",
    "              #linewidth=.5,\n",
    "              #legend=False,\n",
    "              #marker=\"o\",\n",
    "              #size=3.5,\n",
    "              #alpha=.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.4, 0.88))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same, but only best models\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "# choose the task (0D, 1D, or 2D)\n",
    "tag = \"3D\"\n",
    "# choose the colorscheme\n",
    "fill_color = (198/256, 193/256, 80/256)\n",
    "\n",
    "stroke_color = (142/256, 136/256, 58/256)\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "    \"JG1502\",  # LogReg/FP\n",
    "    \"JG1504\",  # XGB/FP\n",
    "    \"JG1508\",  # DMPNN/CGR+RDKit\n",
    "    \"JG1507\",  # DMPNN/CGR\n",
    "\n",
    "]\n",
    "\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(experiment_ids) & df_all['tags'].apply(lambda x: tag in x)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(experiment_ids, itertools.count()))\n",
    "df_plot = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict))\n",
    "ticklabels = df_plot[\"Model+Features\"].unique().tolist()\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(5.6, 4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot, \n",
    "              x=\"Model+Features\",\n",
    "              y=metric,\n",
    "              hue=\"fold\", \n",
    "              palette=sns.color_palette(\"husl\", 9),\n",
    "              #edgecolor=stroke_color,\n",
    "              #color=fill_color,\n",
    "              #linewidth=.5,\n",
    "              #legend=False,\n",
    "              #marker=\"o\",\n",
    "              #size=3.5,\n",
    "              #alpha=.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel(None)\n",
    "ax.xaxis.set_tick_params(labelrotation=90)\n",
    "ax.set_ylim((0.4, 0.88))\n",
    "ax.xaxis.set_ticklabels(df_plot[\"Model+Features\"].drop_duplicates().str.replace(\"LogisticRegression\", \"LogReg\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_{tag}_models_{metric.replace('/', '_')}_line.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.groupby(\"Model+Features\")[\"val/avgPrecision_macro\"].agg([np.mean, np.std]).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the best model significantly better than the rest?\n",
    "best = \"D-MPNN/RDKit\"\n",
    "x = df_plot.loc[df_plot[\"Model+Features\"] == best].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "for i in df_plot[\"Model+Features\"].drop_duplicates():\n",
    "    if i != best:\n",
    "        y = df_plot.loc[df_plot[\"Model+Features\"] == i].sort_values(by=\"run_id\")[\"val/avgPrecision_macro\"].to_numpy()\n",
    "        print(i, \":\\t\", wilcoxon(x, y, alternative=\"two-sided\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette([\"#5790fc\", \"#f89c20\", \"#964a8b\", \"#e42536\"])  # works for colorblind\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some settings for all following plots\n",
    "\n",
    "# order used for hue/style\n",
    "order = ['FFN/OHE', 'XGB/FP', 'XGB/FP+RDKit', 'D-MPNN/CGR', 'D-MPNN/RDKit']\n",
    "\n",
    "# linestyle\n",
    "dashes=[(3, 3), (3, 3), (1, 1), (3, 3), (1, 1)]\n",
    "\n",
    "# alternative palette where two colors are reused with less saturation to show derivative categories\n",
    "palette = sns.color_palette([\"#5790fc\", \"#f89c20\", \"#a66611\", \"#a0228d\", \"#783b6e\"])  # works for colorblind\n",
    "palette = sns.color_palette([\"#5790fc\", \"#f89c20\", \"#a66611\", \"#e42536\", \"#a1212c\"])  # works for colorblind\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1344\",  # FFN/OHE\n",
    "            \"JG1345\",  # XGB/FP\n",
    "            \"JG1346\",  # XGB/FP+RDKit\n",
    "            \"JG1347\",  # D-MPNN/CGR\n",
    "            \"JG1348\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1339\",  # FFN/OHE\n",
    "            \"JG1340\",  # XGB/FP\n",
    "            \"JG1341\",  # XGB/FP+RDKit\n",
    "            \"JG1342\",  # D-MPNN/CGR\n",
    "            \"JG1343\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1334\",  # FFN/OHE\n",
    "            \"JG1335\",  # XGB/FP\n",
    "            \"JG1336\",  # XGB/FP+RDKit\n",
    "            \"JG1337\",  # D-MPNN/CGR\n",
    "            \"JG1338\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1329\",  # FFN/OHE\n",
    "            \"JG1330\",  # XGB/FP\n",
    "            \"JG1331\",  # XGB/FP+RDKit\n",
    "            \"JG1332\",  # D-MPNN/CGR\n",
    "            \"JG1333\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1324\",  # FFN/OHE\n",
    "            \"JG1325\",  # XGB/FP\n",
    "            \"JG1326\",  # XGB/FP+RDKit\n",
    "            \"JG1327\",  # D-MPNN/CGR\n",
    "            \"JG1328\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1319\",  # FFN/OHE\n",
    "            \"JG1320\",  # XGB/FP\n",
    "            \"JG1321\",  # XGB/FP+RDKit\n",
    "            \"JG1322\",  # D-MPNN/CGR\n",
    "            \"JG1323\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1314\",  # FFN/OHE\n",
    "            \"JG1315\",  # XGB/FP\n",
    "            \"JG1316\",  # XGB/FP+RDKit\n",
    "            \"JG1317\",  # D-MPNN/CGR\n",
    "            \"JG1318\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1309\",  # FFN/OHE\n",
    "            \"JG1310\",  # XGB/FP\n",
    "            \"JG1311\",  # XGB/FP+RDKit\n",
    "            \"JG1312\",  # D-MPNN/CGR\n",
    "            \"JG1313\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "# don't plot chance level b/c it is much lower\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax.set_ylim((0.75, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(title=None, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1344\",  # FFN/OHE\n",
    "            \"JG1345\",  # XGB/FP\n",
    "            \"JG1346\",  # XGB/FP+RDKit\n",
    "            \"JG1347\",  # D-MPNN/CGR\n",
    "            \"JG1348\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1339\",  # FFN/OHE\n",
    "            \"JG1340\",  # XGB/FP\n",
    "            \"JG1341\",  # XGB/FP+RDKit\n",
    "            \"JG1342\",  # D-MPNN/CGR\n",
    "            \"JG1343\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1334\",  # FFN/OHE\n",
    "            \"JG1335\",  # XGB/FP\n",
    "            \"JG1336\",  # XGB/FP+RDKit\n",
    "            \"JG1337\",  # D-MPNN/CGR\n",
    "            \"JG1338\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1329\",  # FFN/OHE\n",
    "            \"JG1330\",  # XGB/FP\n",
    "            \"JG1331\",  # XGB/FP+RDKit\n",
    "            \"JG1332\",  # D-MPNN/CGR\n",
    "            \"JG1333\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1324\",  # FFN/OHE\n",
    "            \"JG1325\",  # XGB/FP\n",
    "            \"JG1326\",  # XGB/FP+RDKit\n",
    "            \"JG1327\",  # D-MPNN/CGR\n",
    "            \"JG1328\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1319\",  # FFN/OHE\n",
    "            \"JG1320\",  # XGB/FP\n",
    "            \"JG1321\",  # XGB/FP+RDKit\n",
    "            \"JG1322\",  # D-MPNN/CGR\n",
    "            \"JG1323\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1314\",  # FFN/OHE\n",
    "            \"JG1315\",  # XGB/FP\n",
    "            \"JG1316\",  # XGB/FP+RDKit\n",
    "            \"JG1317\",  # D-MPNN/CGR\n",
    "            \"JG1318\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1309\",  # FFN/OHE\n",
    "            \"JG1310\",  # XGB/FP\n",
    "            \"JG1311\",  # XGB/FP+RDKit\n",
    "            \"JG1312\",  # D-MPNN/CGR\n",
    "            \"JG1313\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "# don't plot chance level b/c it is much lower\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax.set_ylim((0.75, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _0.625\n",
    "            \"JG1344\",  # FFN/OHE\n",
    "            \"JG1345\",  # XGB/FP\n",
    "            \"JG1346\",  # XGB/FP+RDKit\n",
    "            \"JG1347\",  # D-MPNN/CGR\n",
    "            \"JG1348\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _1.25\n",
    "            \"JG1339\",  # FFN/OHE\n",
    "            \"JG1340\",  # XGB/FP\n",
    "            \"JG1341\",  # XGB/FP+RDKit\n",
    "            \"JG1342\",  # D-MPNN/CGR\n",
    "            \"JG1343\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _2.5\n",
    "            \"JG1334\",  # FFN/OHE\n",
    "            \"JG1335\",  # XGB/FP\n",
    "            \"JG1336\",  # XGB/FP+RDKit\n",
    "            \"JG1337\",  # D-MPNN/CGR\n",
    "            \"JG1338\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1329\",  # FFN/OHE\n",
    "            \"JG1330\",  # XGB/FP\n",
    "            \"JG1331\",  # XGB/FP+RDKit\n",
    "            \"JG1332\",  # D-MPNN/CGR\n",
    "            \"JG1333\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1324\",  # FFN/OHE\n",
    "            \"JG1325\",  # XGB/FP\n",
    "            \"JG1326\",  # XGB/FP+RDKit\n",
    "            \"JG1327\",  # D-MPNN/CGR\n",
    "            \"JG1328\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1319\",  # FFN/OHE\n",
    "            \"JG1320\",  # XGB/FP\n",
    "            \"JG1321\",  # XGB/FP+RDKit\n",
    "            \"JG1322\",  # D-MPNN/CGR\n",
    "            \"JG1323\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1314\",  # FFN/OHE\n",
    "            \"JG1315\",  # XGB/FP\n",
    "            \"JG1316\",  # XGB/FP+RDKit\n",
    "            \"JG1317\",  # D-MPNN/CGR\n",
    "            \"JG1318\",  # D-MPNN/CGR+RDKit \n",
    "    ],\n",
    "        [  # _80 (= full)\n",
    "            \"JG1309\",  # FFN/OHE\n",
    "            \"JG1310\",  # XGB/FP\n",
    "            \"JG1311\",  # XGB/FP+RDKit\n",
    "            \"JG1312\",  # D-MPNN/CGR\n",
    "            \"JG1313\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"0D_0.625\", \"0D_1.25\", \"0D_2.5\", \"0D_5\", \"0D_10\",\"0D_20\", \"0D_40\", \"0D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_0D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1375\",  # FFN/OHE\n",
    "            \"JG1376\",  # XGB/FP\n",
    "            \"JG1377\",  # XGB/FP+RDKit\n",
    "            \"JG1378\",  # D-MPNN/CGR\n",
    "            \"JG1379\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1370\",  # FFN/OHE\n",
    "            \"JG1371\",  # XGB/FP\n",
    "            \"JG1372\",  # XGB/FP+RDKit\n",
    "            \"JG1373\",  # D-MPNN/CGR\n",
    "            \"JG1374\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1365\",  # FFN/OHE\n",
    "            \"JG1366\",  # XGB/FP\n",
    "            \"JG1367\",  # XGB/FP+RDKit\n",
    "            \"JG1368\",  # D-MPNN/CGR\n",
    "            \"JG1369\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1360\",  # FFN/OHE\n",
    "            \"JG1361\",  # XGB/FP\n",
    "            \"JG1362\",  # XGB/FP+RDKit\n",
    "            \"JG1363\",  # D-MPNN/CGR\n",
    "            \"JG1364\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1355\",  # FFN/OHE\n",
    "            \"JG1356\",  # XGB/FP\n",
    "            \"JG1357\",  # XGB/FP+RDKit\n",
    "            \"JG1358\",  # D-MPNN/CGR\n",
    "            \"JG1359\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1350\",  # FFN/OHE\n",
    "            \"JG1351\",  # XGB/FP\n",
    "            \"JG1352\",  # XGB/FP+RDKit\n",
    "            \"JG1353\",  # D-MPNN/CGR\n",
    "            \"JG1354\",  # D-MPNN/CGR+RDKit\n",
    "    ], \n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.70, 0.95))\n",
    "ax.set_xticks(\n",
    "    [500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1375\",  # FFN/OHE\n",
    "            \"JG1376\",  # XGB/FP\n",
    "            \"JG1377\",  # XGB/FP+RDKit\n",
    "            \"JG1378\",  # D-MPNN/CGR\n",
    "            \"JG1379\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1370\",  # FFN/OHE\n",
    "            \"JG1371\",  # XGB/FP\n",
    "            \"JG1372\",  # XGB/FP+RDKit\n",
    "            \"JG1373\",  # D-MPNN/CGR\n",
    "            \"JG1374\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1365\",  # FFN/OHE\n",
    "            \"JG1366\",  # XGB/FP\n",
    "            \"JG1367\",  # XGB/FP+RDKit\n",
    "            \"JG1368\",  # D-MPNN/CGR\n",
    "            \"JG1369\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1360\",  # FFN/OHE\n",
    "            \"JG1361\",  # XGB/FP\n",
    "            \"JG1362\",  # XGB/FP+RDKit\n",
    "            \"JG1363\",  # D-MPNN/CGR\n",
    "            \"JG1364\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1355\",  # FFN/OHE\n",
    "            \"JG1356\",  # XGB/FP\n",
    "            \"JG1357\",  # XGB/FP+RDKit\n",
    "            \"JG1358\",  # D-MPNN/CGR\n",
    "            \"JG1359\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1350\",  # FFN/OHE\n",
    "            \"JG1351\",  # XGB/FP\n",
    "            \"JG1352\",  # XGB/FP+RDKit\n",
    "            \"JG1353\",  # D-MPNN/CGR\n",
    "            \"JG1354\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "#sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.70, 0.95))\n",
    "ax.set_xticks(\n",
    "    [500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1375\",  # FFN/OHE\n",
    "            \"JG1376\",  # XGB/FP\n",
    "            \"JG1377\",  # XGB/FP+RDKit\n",
    "            \"JG1378\",  # D-MPNN/CGR\n",
    "            \"JG1379\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1370\",  # FFN/OHE\n",
    "            \"JG1371\",  # XGB/FP\n",
    "            \"JG1372\",  # XGB/FP+RDKit\n",
    "            \"JG1373\",  # D-MPNN/CGR\n",
    "            \"JG1374\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1365\",  # FFN/OHE\n",
    "            \"JG1366\",  # XGB/FP\n",
    "            \"JG1367\",  # XGB/FP+RDKit\n",
    "            \"JG1368\",  # D-MPNN/CGR\n",
    "            \"JG1369\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1360\",  # FFN/OHE\n",
    "            \"JG1361\",  # XGB/FP\n",
    "            \"JG1362\",  # XGB/FP+RDKit\n",
    "            \"JG1363\",  # D-MPNN/CGR\n",
    "            \"JG1364\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1355\",  # FFN/OHE\n",
    "            \"JG1356\",  # XGB/FP\n",
    "            \"JG1357\",  # XGB/FP+RDKit\n",
    "            \"JG1358\",  # D-MPNN/CGR\n",
    "            \"JG1359\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1350\",  # FFN/OHE\n",
    "            \"JG1351\",  # XGB/FP\n",
    "            \"JG1352\",  # XGB/FP+RDKit\n",
    "            \"JG1353\",  # D-MPNN/CGR\n",
    "            \"JG1354\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(\n",
    "    [250, 500, 1000, 2000, 4000, 8000, 16000, 32000], \n",
    "    ['250', '500', '1000', '2000', '4000', '8000', '16000', '32000']\n",
    ")\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but including synthetic data\n",
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [\n",
    "        [  # _2.5\n",
    "            \"JG1375\",  # FFN/OHE\n",
    "            \"JG1376\",  # XGB/FP\n",
    "            \"JG1377\",  # XGB/FP+RDKit\n",
    "            \"JG1378\",  # D-MPNN/CGR\n",
    "            \"JG1379\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _5\n",
    "            \"JG1370\",  # FFN/OHE\n",
    "            \"JG1371\",  # XGB/FP\n",
    "            \"JG1372\",  # XGB/FP+RDKit\n",
    "            \"JG1373\",  # D-MPNN/CGR\n",
    "            \"JG1374\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1365\",  # FFN/OHE\n",
    "            \"JG1366\",  # XGB/FP\n",
    "            \"JG1367\",  # XGB/FP+RDKit\n",
    "            \"JG1368\",  # D-MPNN/CGR\n",
    "            \"JG1369\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1360\",  # FFN/OHE\n",
    "            \"JG1361\",  # XGB/FP\n",
    "            \"JG1362\",  # XGB/FP+RDKit\n",
    "            \"JG1363\",  # D-MPNN/CGR\n",
    "            \"JG1364\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1355\",  # FFN/OHE\n",
    "            \"JG1356\",  # XGB/FP\n",
    "            \"JG1357\",  # XGB/FP+RDKit\n",
    "            \"JG1358\",  # D-MPNN/CGR\n",
    "            \"JG1359\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1350\",  # FFN/OHE\n",
    "            \"JG1351\",  # XGB/FP\n",
    "            \"JG1352\",  # XGB/FP+RDKit\n",
    "            \"JG1353\",  # D-MPNN/CGR\n",
    "            \"JG1354\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80_syn\n",
    "            \"JG1511\",  # FFN/OHE\n",
    "            \"JG1512\",  # XGB/FP\n",
    "            \"JG1513\",  # XGB/FP+RDKit\n",
    "            \"JG1514\",  # D-MPNN/CGR\n",
    "            \"JG1515\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"1D_2.5\", \"1D_5\", \"1D_10\", \"1D_20\", \"1D_40\", \"1D_80\", \"1D_80_syn\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(\n",
    "    [250*2**n for n in range(10)], \n",
    "    [f\"{250*2**n}\" for n in range(10)],\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"lower right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_1D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5\n",
    "            \"JG1420\",  # FFN/OHE\n",
    "            \"JG1421\",  # XGB/FP\n",
    "            \"JG1422\",  # XGB/FP+RDKit\n",
    "            \"JG1423\",  # D-MPNN/CGR\n",
    "            \"JG1424\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1415\",  # FFN/OHE\n",
    "            \"JG1416\",  # XGB/FP\n",
    "            \"JG1417\",  # XGB/FP+RDKit\n",
    "            \"JG1418\",  # D-MPNN/CGR\n",
    "            \"JG1419\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1410\",  # FFN/OHE\n",
    "            \"JG1411\",  # XGB/FP\n",
    "            \"JG1412\",  # XGB/FP+RDKit\n",
    "            \"JG1413\",  # D-MPNN/CGR\n",
    "            \"JG1414\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1405\",  # FFN/OHE\n",
    "            \"JG1406\",  # XGB/FP\n",
    "            \"JG1407\",  # XGB/FP+RDKit\n",
    "            \"JG1408\",  # D-MPNN/CGR\n",
    "            \"JG1409\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1400\",  # FFN/OHE\n",
    "            \"JG1401\",  # XGB/FP\n",
    "            \"JG1402\",  # XGB/FP+RDKit\n",
    "            \"JG1403\",  # D-MPNN/CGR\n",
    "            \"JG1404\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1395\",  # FFN/OHE\n",
    "            \"JG1396\",  # XGB/FP\n",
    "            \"JG1397\",  # XGB/FP+RDKit\n",
    "            \"JG1398\",  # D-MPNN/CGR\n",
    "            \"JG1399\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1390\",  # FFN/OHE\n",
    "            \"JG1391\",  # XGB/FP\n",
    "            \"JG1392\",  # XGB/FP+RDKit\n",
    "            \"JG1393\",  # D-MPNN/CGR\n",
    "            \"JG1394\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1385\",  # FFN/OHE\n",
    "            \"JG1386\",  # XGB/FP\n",
    "            \"JG1387\",  # XGB/FP+RDKit\n",
    "            \"JG1388\",  # D-MPNN/CGR\n",
    "            \"JG1389\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1380\",  # FFN/OHE\n",
    "            \"JG1381\",  # XGB/FP\n",
    "            \"JG1382\",  # XGB/FP+RDKit\n",
    "            \"JG1383\",  # D-MPNN/CGR\n",
    "            \"JG1384\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.53, 0.85))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5\n",
    "            \"JG1420\",  # FFN/OHE\n",
    "            \"JG1421\",  # XGB/FP\n",
    "            \"JG1422\",  # XGB/FP+RDKit\n",
    "            \"JG1423\",  # D-MPNN/CGR\n",
    "            \"JG1424\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1415\",  # FFN/OHE\n",
    "            \"JG1416\",  # XGB/FP\n",
    "            \"JG1417\",  # XGB/FP+RDKit\n",
    "            \"JG1418\",  # D-MPNN/CGR\n",
    "            \"JG1419\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1410\",  # FFN/OHE\n",
    "            \"JG1411\",  # XGB/FP\n",
    "            \"JG1412\",  # XGB/FP+RDKit\n",
    "            \"JG1413\",  # D-MPNN/CGR\n",
    "            \"JG1414\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1405\",  # FFN/OHE\n",
    "            \"JG1406\",  # XGB/FP\n",
    "            \"JG1407\",  # XGB/FP+RDKit\n",
    "            \"JG1408\",  # D-MPNN/CGR\n",
    "            \"JG1409\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1400\",  # FFN/OHE\n",
    "            \"JG1401\",  # XGB/FP\n",
    "            \"JG1402\",  # XGB/FP+RDKit\n",
    "            \"JG1403\",  # D-MPNN/CGR\n",
    "            \"JG1404\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1395\",  # FFN/OHE\n",
    "            \"JG1396\",  # XGB/FP\n",
    "            \"JG1397\",  # XGB/FP+RDKit\n",
    "            \"JG1398\",  # D-MPNN/CGR\n",
    "            \"JG1399\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1390\",  # FFN/OHE\n",
    "            \"JG1391\",  # XGB/FP\n",
    "            \"JG1392\",  # XGB/FP+RDKit\n",
    "            \"JG1393\",  # D-MPNN/CGR\n",
    "            \"JG1394\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1385\",  # FFN/OHE\n",
    "            \"JG1386\",  # XGB/FP\n",
    "            \"JG1387\",  # XGB/FP+RDKit\n",
    "            \"JG1388\",  # D-MPNN/CGR\n",
    "            \"JG1389\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1380\",  # FFN/OHE\n",
    "            \"JG1381\",  # XGB/FP\n",
    "            \"JG1382\",  # XGB/FP+RDKit\n",
    "            \"JG1383\",  # D-MPNN/CGR\n",
    "            \"JG1384\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.85))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5  do not plot because of excessive variance\n",
    "            #\"JG1420\",  # FFN/OHE\n",
    "            #\"JG1421\",  # XGB/FP\n",
    "            #\"JG1422\",  # XGB/FP+RDKit\n",
    "            #\"JG1423\",  # D-MPNN/CGR\n",
    "            #\"JG1424\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1415\",  # FFN/OHE\n",
    "            \"JG1416\",  # XGB/FP\n",
    "            \"JG1417\",  # XGB/FP+RDKit\n",
    "            \"JG1418\",  # D-MPNN/CGR\n",
    "            \"JG1419\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1410\",  # FFN/OHE\n",
    "            \"JG1411\",  # XGB/FP\n",
    "            \"JG1412\",  # XGB/FP+RDKit\n",
    "            \"JG1413\",  # D-MPNN/CGR\n",
    "            \"JG1414\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1405\",  # FFN/OHE\n",
    "            \"JG1406\",  # XGB/FP\n",
    "            \"JG1407\",  # XGB/FP+RDKit\n",
    "            \"JG1408\",  # D-MPNN/CGR\n",
    "            \"JG1409\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1400\",  # FFN/OHE\n",
    "            \"JG1401\",  # XGB/FP\n",
    "            \"JG1402\",  # XGB/FP+RDKit\n",
    "            \"JG1403\",  # D-MPNN/CGR\n",
    "            \"JG1404\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1395\",  # FFN/OHE\n",
    "            \"JG1396\",  # XGB/FP\n",
    "            \"JG1397\",  # XGB/FP+RDKit\n",
    "            \"JG1398\",  # D-MPNN/CGR\n",
    "            \"JG1399\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1390\",  # FFN/OHE\n",
    "            \"JG1391\",  # XGB/FP\n",
    "            \"JG1392\",  # XGB/FP+RDKit\n",
    "            \"JG1393\",  # D-MPNN/CGR\n",
    "            \"JG1394\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1385\",  # FFN/OHE\n",
    "            \"JG1386\",  # XGB/FP\n",
    "            \"JG1387\",  # XGB/FP+RDKit\n",
    "            \"JG1388\",  # D-MPNN/CGR\n",
    "            \"JG1389\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1380\",  # FFN/OHE\n",
    "            \"JG1381\",  # XGB/FP\n",
    "            \"JG1382\",  # XGB/FP+RDKit\n",
    "            \"JG1383\",  # D-MPNN/CGR\n",
    "            \"JG1384\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(9)], \n",
    "    [f\"{125*2**n}\" for n in range(9)],\n",
    ")\n",
    "legend = ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but with synthetic data\n",
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _5  do not plot because of excessive variance\n",
    "            #\"JG1420\",  # FFN/OHE\n",
    "            #\"JG1421\",  # XGB/FP\n",
    "            #\"JG1422\",  # XGB/FP+RDKit\n",
    "            #\"JG1423\",  # D-MPNN/CGR\n",
    "            #\"JG1424\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _7.5\n",
    "            \"JG1415\",  # FFN/OHE\n",
    "            \"JG1416\",  # XGB/FP\n",
    "            \"JG1417\",  # XGB/FP+RDKit\n",
    "            \"JG1418\",  # D-MPNN/CGR\n",
    "            \"JG1419\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _10\n",
    "            \"JG1410\",  # FFN/OHE\n",
    "            \"JG1411\",  # XGB/FP\n",
    "            \"JG1412\",  # XGB/FP+RDKit\n",
    "            \"JG1413\",  # D-MPNN/CGR\n",
    "            \"JG1414\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1405\",  # FFN/OHE\n",
    "            \"JG1406\",  # XGB/FP\n",
    "            \"JG1407\",  # XGB/FP+RDKit\n",
    "            \"JG1408\",  # D-MPNN/CGR\n",
    "            \"JG1409\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1400\",  # FFN/OHE\n",
    "            \"JG1401\",  # XGB/FP\n",
    "            \"JG1402\",  # XGB/FP+RDKit\n",
    "            \"JG1403\",  # D-MPNN/CGR\n",
    "            \"JG1404\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1395\",  # FFN/OHE\n",
    "            \"JG1396\",  # XGB/FP\n",
    "            \"JG1397\",  # XGB/FP+RDKit\n",
    "            \"JG1398\",  # D-MPNN/CGR\n",
    "            \"JG1399\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1390\",  # FFN/OHE\n",
    "            \"JG1391\",  # XGB/FP\n",
    "            \"JG1392\",  # XGB/FP+RDKit\n",
    "            \"JG1393\",  # D-MPNN/CGR\n",
    "            \"JG1394\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1385\",  # FFN/OHE\n",
    "            \"JG1386\",  # XGB/FP\n",
    "            \"JG1387\",  # XGB/FP+RDKit\n",
    "            \"JG1388\",  # D-MPNN/CGR\n",
    "            \"JG1389\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _80\n",
    "            \"JG1380\",  # FFN/OHE\n",
    "            \"JG1381\",  # XGB/FP\n",
    "            \"JG1382\",  # XGB/FP+RDKit\n",
    "            \"JG1383\",  # D-MPNN/CGR\n",
    "            \"JG1384\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60_syn\n",
    "            \"JG1516\",  # FFN/OHE\n",
    "            \"JG1517\",  # XGB/FP\n",
    "            \"JG1518\",  # XGB/FP+RDKit\n",
    "            \"JG1519\",  # D-MPNN/CGR\n",
    "            \"JG1520\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"2D_5\", \"2D_7.5\", \"2D_10\", \"2D_15\", \"2D_20\", \"2D_30\", \"2D_40\", \"2D_60\", \"2D_80\", \"2D_60_syn\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(10)], \n",
    "    [f\"{125*2**n}\" for n in range(10)],\n",
    ")\n",
    "legend = ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_2D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D restricted data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"val/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1475\",  # FFN/OHE\n",
    "            \"JG1476\",  # XGB/FP\n",
    "            \"JG1477\",  # XGB/FP+RDKit\n",
    "            \"JG1478\",  # D-MPNN/CGR\n",
    "            \"JG1479\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1470\",  # FFN/OHE\n",
    "            \"JG1471\",  # XGB/FP\n",
    "            \"JG1472\",  # XGB/FP+RDKit\n",
    "            \"JG1473\",  # D-MPNN/CGR\n",
    "            \"JG1474\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1465\",  # FFN/OHE\n",
    "            \"JG1466\",  # XGB/FP\n",
    "            \"JG1467\",  # XGB/FP+RDKit\n",
    "            \"JG1468\",  # D-MPNN/CGR\n",
    "            \"JG1469\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1460\",  # FFN/OHE\n",
    "            \"JG1461\",  # XGB/FP\n",
    "            \"JG1462\",  # XGB/FP+RDKit\n",
    "            \"JG1463\",  # D-MPNN/CGR\n",
    "            \"JG1464\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1455\",  # FFN/OHE\n",
    "            \"JG1456\",  # XGB/FP\n",
    "            \"JG1457\",  # XGB/FP+RDKit\n",
    "            \"JG1458\",  # D-MPNN/CGR\n",
    "            \"JG1459\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1450\",  # FFN/OHE\n",
    "            \"JG1451\",  # XGB/FP\n",
    "            \"JG1452\",  # XGB/FP+RDKit\n",
    "            \"JG1453\",  # D-MPNN/CGR\n",
    "            \"JG1454\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1445\",  # FFN/OHE\n",
    "            \"JG1446\",  # XGB/FP\n",
    "            \"JG1447\",  # XGB/FP+RDKit\n",
    "            \"JG1448\",  # D-MPNN/CGR\n",
    "            \"JG1449\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1440\",  # FFN/OHE\n",
    "            \"JG1441\",  # XGB/FP\n",
    "            \"JG1442\",  # XGB/FP+RDKit\n",
    "            \"JG1443\",  # D-MPNN/CGR\n",
    "            \"JG1444\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1435\",  # FFN/OHE\n",
    "            \"JG1436\",  # XGB/FP\n",
    "            \"JG1437\",  # XGB/FP+RDKit\n",
    "            \"JG1438\",  # D-MPNN/CGR\n",
    "            \"JG1439\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1430\",  # FFN/OHE\n",
    "            \"JG1431\",  # XGB/FP\n",
    "            \"JG1432\",  # XGB/FP+RDKit\n",
    "            \"JG1433\",  # D-MPNN/CGR\n",
    "            \"JG1434\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "#        [  # _80  # do not plot b/c excessive variance\n",
    "#            \"JG1425\",  # FFN/OHE\n",
    "#            \"JG1426\",  # XGB/FP\n",
    "#            \"JG1427\",  # XGB/FP+RDKit\n",
    "#            \"JG1428\",  # D-MPNN/CGR\n",
    "#            \"JG1429\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "]\n",
    "\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"val\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.9))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1475\",  # FFN/OHE\n",
    "            \"JG1476\",  # XGB/FP\n",
    "            \"JG1477\",  # XGB/FP+RDKit\n",
    "            \"JG1478\",  # D-MPNN/CGR\n",
    "            \"JG1479\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1470\",  # FFN/OHE\n",
    "            \"JG1471\",  # XGB/FP\n",
    "            \"JG1472\",  # XGB/FP+RDKit\n",
    "            \"JG1473\",  # D-MPNN/CGR\n",
    "            \"JG1474\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1465\",  # FFN/OHE\n",
    "            \"JG1466\",  # XGB/FP\n",
    "            \"JG1467\",  # XGB/FP+RDKit\n",
    "            \"JG1468\",  # D-MPNN/CGR\n",
    "            \"JG1469\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1460\",  # FFN/OHE\n",
    "            \"JG1461\",  # XGB/FP\n",
    "            \"JG1462\",  # XGB/FP+RDKit\n",
    "            \"JG1463\",  # D-MPNN/CGR\n",
    "            \"JG1464\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1455\",  # FFN/OHE\n",
    "            \"JG1456\",  # XGB/FP\n",
    "            \"JG1457\",  # XGB/FP+RDKit\n",
    "            \"JG1458\",  # D-MPNN/CGR\n",
    "            \"JG1459\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1450\",  # FFN/OHE\n",
    "            \"JG1451\",  # XGB/FP\n",
    "            \"JG1452\",  # XGB/FP+RDKit\n",
    "            \"JG1453\",  # D-MPNN/CGR\n",
    "            \"JG1454\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1445\",  # FFN/OHE\n",
    "            \"JG1446\",  # XGB/FP\n",
    "            \"JG1447\",  # XGB/FP+RDKit\n",
    "            \"JG1448\",  # D-MPNN/CGR\n",
    "            \"JG1449\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1440\",  # FFN/OHE\n",
    "            \"JG1441\",  # XGB/FP\n",
    "            \"JG1442\",  # XGB/FP+RDKit\n",
    "            \"JG1443\",  # D-MPNN/CGR\n",
    "            \"JG1444\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1435\",  # FFN/OHE\n",
    "            \"JG1436\",  # XGB/FP\n",
    "            \"JG1437\",  # XGB/FP+RDKit\n",
    "            \"JG1438\",  # D-MPNN/CGR\n",
    "            \"JG1439\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1430\",  # FFN/OHE\n",
    "            \"JG1431\",  # XGB/FP\n",
    "            \"JG1432\",  # XGB/FP+RDKit\n",
    "            \"JG1433\",  # D-MPNN/CGR\n",
    "            \"JG1434\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "#        [  # _80  # do not plot b/c excessive variance\n",
    "#            \"JG1425\",  # FFN/OHE\n",
    "#            \"JG1426\",  # XGB/FP\n",
    "#            \"JG1427\",  # XGB/FP+RDKit\n",
    "#            \"JG1428\",  # D-MPNN/CGR\n",
    "#            \"JG1429\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    dashes=dashes,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.85))\n",
    "ax.set_xticks(\n",
    "    [32*2**n for n in range(10)], \n",
    "    [f\"{32*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition of the last plot, but with number of seen building blocks on the x axis instead of training samples\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "        [  # _10\n",
    "            \"JG1475\",  # FFN/OHE\n",
    "            \"JG1476\",  # XGB/FP\n",
    "            \"JG1477\",  # XGB/FP+RDKit\n",
    "            \"JG1478\",  # D-MPNN/CGR\n",
    "            \"JG1479\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _15\n",
    "            \"JG1470\",  # FFN/OHE\n",
    "            \"JG1471\",  # XGB/FP\n",
    "            \"JG1472\",  # XGB/FP+RDKit\n",
    "            \"JG1473\",  # D-MPNN/CGR\n",
    "            \"JG1474\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1465\",  # FFN/OHE\n",
    "            \"JG1466\",  # XGB/FP\n",
    "            \"JG1467\",  # XGB/FP+RDKit\n",
    "            \"JG1468\",  # D-MPNN/CGR\n",
    "            \"JG1469\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1460\",  # FFN/OHE\n",
    "            \"JG1461\",  # XGB/FP\n",
    "            \"JG1462\",  # XGB/FP+RDKit\n",
    "            \"JG1463\",  # D-MPNN/CGR\n",
    "            \"JG1464\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1455\",  # FFN/OHE\n",
    "            \"JG1456\",  # XGB/FP\n",
    "            \"JG1457\",  # XGB/FP+RDKit\n",
    "            \"JG1458\",  # D-MPNN/CGR\n",
    "            \"JG1459\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1450\",  # FFN/OHE\n",
    "            \"JG1451\",  # XGB/FP\n",
    "            \"JG1452\",  # XGB/FP+RDKit\n",
    "            \"JG1453\",  # D-MPNN/CGR\n",
    "            \"JG1454\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1445\",  # FFN/OHE\n",
    "            \"JG1446\",  # XGB/FP\n",
    "            \"JG1447\",  # XGB/FP+RDKit\n",
    "            \"JG1448\",  # D-MPNN/CGR\n",
    "            \"JG1449\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1440\",  # FFN/OHE\n",
    "            \"JG1441\",  # XGB/FP\n",
    "            \"JG1442\",  # XGB/FP+RDKit\n",
    "            \"JG1443\",  # D-MPNN/CGR\n",
    "            \"JG1444\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1435\",  # FFN/OHE\n",
    "            \"JG1436\",  # XGB/FP\n",
    "            \"JG1437\",  # XGB/FP+RDKit\n",
    "            \"JG1438\",  # D-MPNN/CGR\n",
    "            \"JG1439\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1430\",  # FFN/OHE\n",
    "            \"JG1431\",  # XGB/FP\n",
    "            \"JG1432\",  # XGB/FP+RDKit\n",
    "            \"JG1433\",  # D-MPNN/CGR\n",
    "            \"JG1434\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "#        [  # _80  # do not plot b/c excessive variance\n",
    "#            \"JG1425\",  # FFN/OHE\n",
    "#            \"JG1426\",  # XGB/FP\n",
    "#            \"JG1427\",  # XGB/FP+RDKit\n",
    "#            \"JG1428\",  # D-MPNN/CGR\n",
    "#            \"JG1429\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_buildingblock_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\"]\n",
    "}\n",
    "\n",
    "chance_level = [get_chance_ap(k, set_type=\"test\") for k in sample_counts.keys()]  # same order as sample_counts\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(4.75,4))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=metric,\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    dashes=dashes,\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "sns.lineplot(x=sample_counts.values(), y=chance_level, c=\"black\", label=\"Chance level\")\n",
    "\n",
    "ax.set_xlabel(\"Training data unique building blocks\")\n",
    "ax.set_ylabel(\"AUPRC\")\n",
    "#ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0.5, 0.85))\n",
    "#ax.set_xticks(\n",
    "#    [32*2**n for n in range(10)], \n",
    "#    [f\"{32*2**n}\" for n in range(10)],\n",
    "#)\n",
    "ax.legend(loc=\"center right\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.svg\", format=\"svg\")\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "#        [  # _10  # do not plot b/c XGB results not available\n",
    "#            \"JG1475\",  # FFN/OHE\n",
    "#            \"JG1476\",  # XGB/FP\n",
    "#            \"JG1477\",  # XGB/FP+RDKit\n",
    "#            \"JG1478\",  # D-MPNN/CGR\n",
    "#            \"JG1479\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "        [  # _15\n",
    "            \"JG1470\",  # FFN/OHE\n",
    "            \"JG1471\",  # XGB/FP\n",
    "            \"JG1472\",  # XGB/FP+RDKit\n",
    "            \"JG1473\",  # D-MPNN/CGR\n",
    "            \"JG1474\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1465\",  # FFN/OHE\n",
    "            \"JG1466\",  # XGB/FP\n",
    "            \"JG1467\",  # XGB/FP+RDKit\n",
    "            \"JG1468\",  # D-MPNN/CGR\n",
    "            \"JG1469\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1460\",  # FFN/OHE\n",
    "            \"JG1461\",  # XGB/FP\n",
    "            \"JG1462\",  # XGB/FP+RDKit\n",
    "            \"JG1463\",  # D-MPNN/CGR\n",
    "            \"JG1464\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1455\",  # FFN/OHE\n",
    "            \"JG1456\",  # XGB/FP\n",
    "            \"JG1457\",  # XGB/FP+RDKit\n",
    "            \"JG1458\",  # D-MPNN/CGR\n",
    "            \"JG1459\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1450\",  # FFN/OHE\n",
    "            \"JG1451\",  # XGB/FP\n",
    "            \"JG1452\",  # XGB/FP+RDKit\n",
    "            \"JG1453\",  # D-MPNN/CGR\n",
    "            \"JG1454\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1445\",  # FFN/OHE\n",
    "            \"JG1446\",  # XGB/FP\n",
    "            \"JG1447\",  # XGB/FP+RDKit\n",
    "            \"JG1448\",  # D-MPNN/CGR\n",
    "            \"JG1449\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1440\",  # FFN/OHE\n",
    "            \"JG1441\",  # XGB/FP\n",
    "            \"JG1442\",  # XGB/FP+RDKit\n",
    "            \"JG1443\",  # D-MPNN/CGR\n",
    "            \"JG1444\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1435\",  # FFN/OHE\n",
    "            \"JG1436\",  # XGB/FP\n",
    "            \"JG1437\",  # XGB/FP+RDKit\n",
    "            \"JG1438\",  # D-MPNN/CGR\n",
    "            \"JG1439\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1430\",  # FFN/OHE\n",
    "            \"JG1431\",  # XGB/FP\n",
    "            \"JG1432\",  # XGB/FP+RDKit\n",
    "            \"JG1433\",  # D-MPNN/CGR\n",
    "            \"JG1434\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "#        [  # _80  # do not plot b/c excessive variance\n",
    "#            \"JG1425\",  # FFN/OHE\n",
    "#            \"JG1426\",  # XGB/FP\n",
    "#            \"JG1427\",  # XGB/FP+RDKit\n",
    "#            \"JG1428\",  # D-MPNN/CGR\n",
    "#            \"JG1429\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1.))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(9)], \n",
    "    [f\"{125*2**n}\" for n in range(9)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but including synthetic data\n",
    "# Plot scaled using chance level for better comparability across sizes\n",
    "# i.e. we divide by the chance level so that the chance result is now 0 and best is still 1\n",
    "# choose the metric, i.e. accuracy or AUROC\n",
    "metric = \"test/avgPrecision_macro\"\n",
    "\n",
    "# choose the data to plot\n",
    "# choose the data to plot\n",
    "experiment_ids = [        \n",
    "#        [  # _10  # do not plot b/c XGB results not available\n",
    "#            \"JG1475\",  # FFN/OHE\n",
    "#            \"JG1476\",  # XGB/FP\n",
    "#            \"JG1477\",  # XGB/FP+RDKit\n",
    "#            \"JG1478\",  # D-MPNN/CGR\n",
    "#            \"JG1479\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "        [  # _15\n",
    "            \"JG1470\",  # FFN/OHE\n",
    "            \"JG1471\",  # XGB/FP\n",
    "            \"JG1472\",  # XGB/FP+RDKit\n",
    "            \"JG1473\",  # D-MPNN/CGR\n",
    "            \"JG1474\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _20\n",
    "            \"JG1465\",  # FFN/OHE\n",
    "            \"JG1466\",  # XGB/FP\n",
    "            \"JG1467\",  # XGB/FP+RDKit\n",
    "            \"JG1468\",  # D-MPNN/CGR\n",
    "            \"JG1469\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _25\n",
    "            \"JG1460\",  # FFN/OHE\n",
    "            \"JG1461\",  # XGB/FP\n",
    "            \"JG1462\",  # XGB/FP+RDKit\n",
    "            \"JG1463\",  # D-MPNN/CGR\n",
    "            \"JG1464\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _30\n",
    "            \"JG1455\",  # FFN/OHE\n",
    "            \"JG1456\",  # XGB/FP\n",
    "            \"JG1457\",  # XGB/FP+RDKit\n",
    "            \"JG1458\",  # D-MPNN/CGR\n",
    "            \"JG1459\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _34\n",
    "            \"JG1450\",  # FFN/OHE\n",
    "            \"JG1451\",  # XGB/FP\n",
    "            \"JG1452\",  # XGB/FP+RDKit\n",
    "            \"JG1453\",  # D-MPNN/CGR\n",
    "            \"JG1454\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _40\n",
    "            \"JG1445\",  # FFN/OHE\n",
    "            \"JG1446\",  # XGB/FP\n",
    "            \"JG1447\",  # XGB/FP+RDKit\n",
    "            \"JG1448\",  # D-MPNN/CGR\n",
    "            \"JG1449\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _50\n",
    "            \"JG1440\",  # FFN/OHE\n",
    "            \"JG1441\",  # XGB/FP\n",
    "            \"JG1442\",  # XGB/FP+RDKit\n",
    "            \"JG1443\",  # D-MPNN/CGR\n",
    "            \"JG1444\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _60\n",
    "            \"JG1435\",  # FFN/OHE\n",
    "            \"JG1436\",  # XGB/FP\n",
    "            \"JG1437\",  # XGB/FP+RDKit\n",
    "            \"JG1438\",  # D-MPNN/CGR\n",
    "            \"JG1439\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "        [  # _70\n",
    "            \"JG1430\",  # FFN/OHE\n",
    "            \"JG1431\",  # XGB/FP\n",
    "            \"JG1432\",  # XGB/FP+RDKit\n",
    "            \"JG1433\",  # D-MPNN/CGR\n",
    "            \"JG1434\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "#        [  # _80  # do not plot b/c excessive variance\n",
    "#            \"JG1425\",  # FFN/OHE\n",
    "#            \"JG1426\",  # XGB/FP\n",
    "#            \"JG1427\",  # XGB/FP+RDKit\n",
    "#            \"JG1428\",  # D-MPNN/CGR\n",
    "#            \"JG1429\",  # D-MPNN/CGR+RDKit\n",
    "#    ],\n",
    "        [  # _60_syn\n",
    "            \"JG1521\",  # FFN/OHE\n",
    "            \"JG1522\",  # XGB/FP\n",
    "            \"JG1523\",  # XGB/FP+RDKit\n",
    "            \"JG1524\",  # D-MPNN/CGR\n",
    "            \"JG1525\",  # D-MPNN/CGR+RDKit\n",
    "    ],\n",
    "]\n",
    "\n",
    "sample_counts = {  # mean number of training samples for each split \n",
    "    k: get_sample_count(k)\n",
    "    for k in [\"3D_10\", \"3D_15\", \"3D_20\", \"3D_25\", \"3D_30\", \"3D_34\", \"3D_40\", \"3D_50\", \"3D_60\", \"3D_70\", \"3D_60_syn\"]\n",
    "}\n",
    "\n",
    "exps = [i for exp in experiment_ids for i in exp]\n",
    "# filter the data\n",
    "df_plot = df_all.loc[df_all['experiment_id'].isin(exps)]\n",
    "\n",
    "# sort the values\n",
    "sort_dict = dict(zip(exps, itertools.count()))\n",
    "df_plot_x = df_plot.sort_values(by=\"experiment_id\", kind=\"mergesort\", key=lambda x: x.map(sort_dict)).copy()\n",
    "df_plot_x[\"x\"] = df_plot_x[\"tags\"].apply(lambda x: sample_counts[x[0]])\n",
    "\n",
    "# divide by chance level. Note that we obtain the chance level per individual fold so that the SEM still makes sense after scaling.\n",
    "df_plot_x[f\"{metric}_scaled\"] = (df_plot_x[metric] - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1)) / (1 - df_plot_x.apply(lambda x: get_chance_ap(x[\"tags\"][0], x[\"fold\"], \"test\"), axis=1))\n",
    "\n",
    "# set plot\n",
    "fig, ax = plt.subplots(figsize=(3.625, 3))\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df_plot_x, \n",
    "    x=\"x\",\n",
    "    y=f\"{metric}_scaled\",\n",
    "    palette=palette,\n",
    "    hue_order=order,\n",
    "    style_order=order,\n",
    "    style=\"Model+Features\",\n",
    "    hue=\"Model+Features\",\n",
    "    errorbar=errorbar,\n",
    "    err_style=\"bars\",\n",
    "    dashes=dashes,\n",
    "    linewidth=linewidth,\n",
    "    markers=[\"o\", \"^\", \"s\", \"<\", \"p\"],\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Training data size\")\n",
    "ax.set_ylabel(\"AUPRC (relative improvement over chance)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_tick_params(labelrotation=0)\n",
    "ax.set_ylim((0., 1.))\n",
    "ax.set_xticks(\n",
    "    [125*2**n for n in range(10)], \n",
    "    [f\"{125*2**n}\" for n in range(10)],\n",
    ")\n",
    "ax.legend(loc=\"upper left\", title=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.svg\", format=\"svg\", transparent=True)\n",
    "fig.savefig(analysis_dir / f\"metrics_{datadate}_3D_restricted-data_models_{metric.replace('/', '_')}_relative_withsynthetic.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
